{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pirate Pain Challenge â€” Optimized GRU Model\n",
        "\n",
        "This notebook trains a **bidirectional GRU** model optimized to achieve >96% accuracy on the pirate pain dataset. Key optimizations include:\n",
        "\n",
        "- **Class weights + label smoothing** for handling imbalanced classes\n",
        "- **Bidirectional GRU** for capturing temporal patterns in both directions\n",
        "- **Learning rate scheduling** with ReduceLROnPlateau\n",
        "- **Optimized hyperparameters** (deeper network, tuned dropout, regularization)\n",
        "- **Enhanced training loop** with better monitoring\n",
        "\n",
        "The pipeline covers data preparation, model training, validation, and inference for Kaggle submissions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Overview\n",
        "\n",
        "- Source files live in the `dataset/` folder provided for Challenge 1.\n",
        "- Each `sample_index` corresponds to a subject; each subject has 180 time steps.\n",
        "- Feature groups: survey-based pain proxies, categorical body traits, and 31 joint-angle measurements.\n",
        "- Labels are stored separately in `pirate_pain_train_labels.csv`.\n",
        "\n",
        "We will build 3D tensors of shape `(n_samples, sequence_length, n_features)` that PyTorch can process with recurrent layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core libs we rely on throughout the notebook\n",
        "import os\n",
        "import random\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "\n",
        "# Data wrangling + math helpers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# PyTorch goodies\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Metrics and validation helpers from scikit-learn\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "\n",
        "# Plotting setup\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Make results repeatable so teammates get the same numbers\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Check whether we have a GPU handy; fall back to CPU otherwise\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Keep plots consistent and readable\n",
        "sns.set(style=\"whitegrid\", context=\"notebook\", palette=\"deep\")\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
        "\n",
        "# All raw files are shipped inside the dataset/ folder\n",
        "data_dir = Path(\"dataset\")\n",
        "assert data_dir.exists(), \"The dataset directory was not found.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the preprocessed tensors so we can skip the heavy CSV wrangling\n",
        "dataset_path = Path(\"dataset.pt\")\n",
        "build_script = Path(\"build_dataset_pt.py\")\n",
        "EXPECTED_WINDOW = 50\n",
        "EXPECTED_STRIDE = 10\n",
        "\n",
        "if not dataset_path.exists():\n",
        "    if build_script.exists():\n",
        "        print(f\"dataset.pt not found. Building a fresh bundle via {build_script} ...\")\n",
        "        subprocess.run(\n",
        "            [\"python\", str(build_script), \"--data-dir\", str(data_dir), \"--output\", str(dataset_path),\n",
        "             \"--window-size\", str(EXPECTED_WINDOW), \"--stride\", str(EXPECTED_STRIDE)],\n",
        "            check=True,\n",
        "        )\n",
        "    else:\n",
        "        raise FileNotFoundError(\n",
        "            f\"dataset.pt not found and build_dataset_pt.py is missing. Ensure the bundle exists at {dataset_path}.\"\n",
        "        )\n",
        "\n",
        "try:\n",
        "    bundle = torch.load(dataset_path, map_location=\"cpu\")\n",
        "except RuntimeError as err:\n",
        "    if \"PytorchStreamReader\" in str(err) and build_script.exists():\n",
        "        print(\"Existing dataset.pt appears to be corrupted. Rebuilding...\")\n",
        "        subprocess.run(\n",
        "            [\"python\", str(build_script), \"--data-dir\", str(data_dir), \"--output\", str(dataset_path),\n",
        "             \"--window-size\", str(EXPECTED_WINDOW), \"--stride\", str(EXPECTED_STRIDE)],\n",
        "            check=True,\n",
        "        )\n",
        "        bundle = torch.load(dataset_path, map_location=\"cpu\")\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "# Ensure window/stride match the expected preprocessing; rebuild if not\n",
        "current_window = bundle.get(\"window_size\")\n",
        "current_stride = bundle.get(\"stride\")\n",
        "if (current_window, current_stride) != (EXPECTED_WINDOW, EXPECTED_STRIDE) and build_script.exists():\n",
        "    print(\n",
        "        f\"dataset.pt built with window={current_window}, stride={current_stride}. Rebuilding with \"\n",
        "        f\"window={EXPECTED_WINDOW}, stride={EXPECTED_STRIDE} for alignment...\"\n",
        "    )\n",
        "    subprocess.run(\n",
        "        [\n",
        "            \"python\",\n",
        "            str(build_script),\n",
        "            \"--data-dir\",\n",
        "            str(data_dir),\n",
        "            \"--output\",\n",
        "            str(dataset_path),\n",
        "            \"--window-size\",\n",
        "            str(EXPECTED_WINDOW),\n",
        "            \"--stride\",\n",
        "            str(EXPECTED_STRIDE),\n",
        "        ],\n",
        "        check=True,\n",
        "    )\n",
        "    bundle = torch.load(dataset_path, map_location=\"cpu\")\n",
        "\n",
        "X_train = bundle[\"X_train\"].clone().detach().float()\n",
        "y_train = bundle[\"y_train\"].clone().detach().view(-1).long()\n",
        "X_val = bundle[\"X_val\"].clone().detach().float()\n",
        "y_val = bundle[\"y_val\"].clone().detach().view(-1).long()\n",
        "X_test = bundle[\"X_test\"].clone().detach().float()\n",
        "y_test = bundle.get(\"y_test\")\n",
        "if y_test is None:\n",
        "    raise KeyError(\"y_test not found in dataset bundle. Please rebuild dataset.pt with the updated script.\")\n",
        "y_test = y_test.clone().detach().view(-1).long()\n",
        "\n",
        "X_inference = bundle.get(\"X_inference\")\n",
        "inference_window_ids = bundle.get(\"inference_window_ids\")\n",
        "kaggle_ids = bundle.get(\"kaggle_ids\")\n",
        "\n",
        "# Try to recover label metadata from the bundle; fall back gracefully if missing\n",
        "label_mapping = bundle.get(\"label_mapping\")\n",
        "idx_to_label = bundle.get(\"idx_to_label\")\n",
        "\n",
        "if idx_to_label is None and label_mapping is not None:\n",
        "    idx_to_label = {int(v): str(k) for k, v in label_mapping.items()}\n",
        "\n",
        "if label_mapping is None and idx_to_label is not None:\n",
        "    label_mapping = {str(v): int(k) for k, v in idx_to_label.items()}\n",
        "\n",
        "if idx_to_label is None:\n",
        "    # Default ordering if the bundle didn't carry the mapping\n",
        "    default_labels = [\"no_pain\", \"low_pain\", \"high_pain\"]\n",
        "    idx_to_label = {idx: name for idx, name in enumerate(default_labels)}\n",
        "    label_mapping = {name: idx for idx, name in idx_to_label.items()}\n",
        "\n",
        "# Keep the Kaggle template handy for later submission\n",
        "sample_submission = pd.read_csv(data_dir / \"sample_submission.csv\", dtype={\"sample_index\": str})\n",
        "if kaggle_ids is None:\n",
        "    kaggle_ids = sample_submission[\"sample_index\"].tolist()\n",
        "\n",
        "print(f\"Train tensor shape: {tuple(X_train.shape)}\")\n",
        "print(f\"Validation tensor shape: {tuple(X_val.shape)}\")\n",
        "print(f\"Test tensor shape: {tuple(X_test.shape)}\")\n",
        "if X_inference is not None:\n",
        "    print(f\"Inference tensor shape: {tuple(X_inference.shape)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate class frequencies for weighted loss (critical for imbalanced dataset)\n",
        "counts = torch.bincount(y_train.cpu()).numpy()\n",
        "total = counts.sum()\n",
        "class_frequencies = counts / total\n",
        "\n",
        "print(\"Label distribution:\")\n",
        "for idx, count in enumerate(counts):\n",
        "    freq = class_frequencies[idx]\n",
        "    print(f\"- {idx_to_label.get(idx, idx)}: {count} ({freq:.2%})\")\n",
        "\n",
        "# Compute class weights: MORE AGGRESSIVE weighting for minority classes\n",
        "# Using square root of inverse frequency for better balance\n",
        "# This gives even more emphasis to minority classes (high_pain)\n",
        "class_weights_base = 1.0 / class_frequencies\n",
        "class_weights = torch.tensor(np.sqrt(class_weights_base), dtype=torch.float32).to(device)\n",
        "# Normalize to prevent extreme values\n",
        "class_weights = class_weights / class_weights.mean() * num_classes\n",
        "\n",
        "print(f\"\\nClass weights (sqrt-normalized): {class_weights.cpu().numpy()}\")\n",
        "print(f\"Original inverse frequency weights: {class_weights_base}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "EVAL_BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "def make_loader(dataset, batch_size, shuffle, drop_last):\n",
        "    \"\"\"Wrap tensors in a DataLoader mirroring the GRU/LSTM notebooks.\"\"\"\n",
        "    cpu_cores = os.cpu_count() or 2\n",
        "    num_workers = max(2, min(4, cpu_cores))\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
        "        prefetch_factor=4,\n",
        "    )\n",
        "\n",
        "train_ds = TensorDataset(X_train, y_train)\n",
        "val_ds = TensorDataset(X_val, y_val)\n",
        "test_ds = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = make_loader(train_ds, BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "val_loader = make_loader(val_ds, EVAL_BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "test_loader = make_loader(test_ds, EVAL_BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "inference_loader = None\n",
        "if X_inference is not None:\n",
        "    inference_ds = TensorDataset(X_inference)\n",
        "    inference_loader = make_loader(inference_ds, EVAL_BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "# Handy metadata for configuring the model\n",
        "input_size = X_train.shape[-1]\n",
        "num_classes = len(idx_to_label)\n",
        "sequence_length = X_train.shape[1]\n",
        "print(f\"Input size: {input_size}, sequence length: {sequence_length}, classes: {num_classes}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fetch a batch to capture the per-sample input shape for summaries\n",
        "for xb, yb in train_loader:\n",
        "    input_shape = xb.shape[1:]\n",
        "    num_classes = len(np.unique(yb.cpu().numpy()))\n",
        "    break\n",
        "\n",
        "print(f\"Input shape per sample: {input_shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def recurrent_summary(model, input_size):\n",
        "    \"\"\"Utility that mimics torchinfo summary for recurrent stacks.\"\"\"\n",
        "    output_shapes = {}\n",
        "    hooks = []\n",
        "\n",
        "    def get_hook(name):\n",
        "        def hook(module, _inp, output):\n",
        "            if isinstance(output, tuple):\n",
        "                shape1 = list(output[0].shape)\n",
        "                shape1[0] = -1\n",
        "                if isinstance(output[1], tuple):\n",
        "                    shape2 = list(output[1][0].shape)\n",
        "                else:\n",
        "                    shape2 = list(output[1].shape)\n",
        "                shape2[1] = -1\n",
        "                output_shapes[name] = f\"[{shape1}, {shape2}]\"\n",
        "            else:\n",
        "                shape = list(output.shape)\n",
        "                shape[0] = -1\n",
        "                output_shapes[name] = f\"{shape}\"\n",
        "        return hook\n",
        "\n",
        "    try:\n",
        "        device = next(model.parameters()).device\n",
        "    except StopIteration:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    dummy_input = torch.randn(1, *input_size).to(device)\n",
        "\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, (nn.Linear, nn.RNN, nn.GRU, nn.LSTM)):\n",
        "            hooks.append(module.register_forward_hook(get_hook(name)))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        model(dummy_input)\n",
        "\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "\n",
        "    print(\"-\" * 79)\n",
        "    print(f\"{'Layer (type)':<25} {'Output Shape':<28} {'Param #':<18}\")\n",
        "    print(\"=\" * 79)\n",
        "    total_params = 0\n",
        "    trainable_params = 0\n",
        "\n",
        "    for name, module in model.named_children():\n",
        "        if name in output_shapes:\n",
        "            module_params = sum(p.numel() for p in module.parameters())\n",
        "            module_trainable = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "            total_params += module_params\n",
        "            trainable_params += module_trainable\n",
        "            layer_name = f\"{name} ({type(module).__name__})\"\n",
        "            print(f\"{layer_name:<25} {output_shapes[name]:<28} {module_trainable:<15}\")\n",
        "\n",
        "    print(\"=\" * 79)\n",
        "    print(f\"Total params: {total_params:,}\")\n",
        "    print(f\"Trainable params: {trainable_params:,}\")\n",
        "    print(f\"Non-trainable params: {total_params - trainable_params:,}\")\n",
        "    print(\"-\" * 79)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"Focal Loss for addressing class imbalance by focusing on hard examples.\n",
        "    \n",
        "    FL(p_t) = -alpha_t * (1 - p_t)^gamma * log(p_t)\n",
        "    where p_t is the predicted probability for the true class.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha  # Class weights\n",
        "        self.gamma = gamma  # Focusing parameter\n",
        "        self.reduction = reduction\n",
        "        \n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = nn.functional.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)  # Probability of true class\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "        \n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        return focal_loss\n",
        "\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    \"\"\"Attention mechanism to focus on important time steps.\"\"\"\n",
        "    def __init__(self, hidden_size: int, bidirectional: bool = False):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size * 2 if bidirectional else hidden_size\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size, self.hidden_size // 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(self.hidden_size // 2, 1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, rnn_out: torch.Tensor) -> torch.Tensor:\n",
        "        # rnn_out: (batch, seq_len, hidden_size)\n",
        "        attn_weights = self.attention(rnn_out)  # (batch, seq_len, 1)\n",
        "        attn_weights = torch.softmax(attn_weights, dim=1)\n",
        "        # Weighted sum\n",
        "        attended = torch.sum(attn_weights * rnn_out, dim=1)  # (batch, hidden_size)\n",
        "        return attended\n",
        "\n",
        "\n",
        "class RecurrentClassifier(nn.Module):\n",
        "    \"\"\"Generic recurrent classifier with optional attention mechanism.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        num_classes: int,\n",
        "        rnn_type: str = \"RNN\",\n",
        "        bidirectional: bool = False,\n",
        "        dropout_rate: float = 0.0,\n",
        "        use_attention: bool = True,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bidirectional = bidirectional\n",
        "        self.use_attention = use_attention\n",
        "\n",
        "        rnn_map = {\n",
        "            \"RNN\": nn.RNN,\n",
        "            \"LSTM\": nn.LSTM,\n",
        "            \"GRU\": nn.GRU,\n",
        "        }\n",
        "        if rnn_type not in rnn_map:\n",
        "            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n",
        "\n",
        "        rnn_module = rnn_map[rnn_type]\n",
        "        dropout_val = dropout_rate if num_layers > 1 else 0.0\n",
        "        self.rnn = rnn_module(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional,\n",
        "            dropout=dropout_val,\n",
        "        )\n",
        "\n",
        "        classifier_input = hidden_size * 2 if bidirectional else hidden_size\n",
        "        \n",
        "        # Add attention mechanism\n",
        "        if use_attention:\n",
        "            self.attention = AttentionLayer(hidden_size, bidirectional)\n",
        "        \n",
        "        # Enhanced classifier with more capacity\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(classifier_input, classifier_input),\n",
        "            nn.LayerNorm(classifier_input),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate * 0.5),\n",
        "            nn.Linear(classifier_input, classifier_input // 2),\n",
        "            nn.LayerNorm(classifier_input // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate * 0.3),\n",
        "            nn.Linear(classifier_input // 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        rnn_out, hidden = self.rnn(x)\n",
        "\n",
        "        if self.rnn_type == \"LSTM\":\n",
        "            hidden = hidden[0]\n",
        "\n",
        "        if self.use_attention:\n",
        "            # Use attention over all time steps\n",
        "            hidden_to_classify = self.attention(rnn_out)\n",
        "        else:\n",
        "            # Use last hidden state (original approach)\n",
        "            if self.bidirectional:\n",
        "                hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n",
        "                hidden_to_classify = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n",
        "            else:\n",
        "                hidden_to_classify = hidden[-1]\n",
        "\n",
        "        return self.classifier(hidden_to_classify)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def move_batch(batch):\n",
        "    if isinstance(batch, (list, tuple)):\n",
        "        return [tensor.to(device) for tensor in batch]\n",
        "    return batch.to(device)\n",
        "\n",
        "\n",
        "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0.0, l2_lambda=0.0, use_augmentation=False, aug_noise_std=0.01):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_predictions, all_targets = [], []\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = move_batch((inputs, targets))\n",
        "        \n",
        "        # Training data augmentation: add small noise\n",
        "        if use_augmentation and model.training:\n",
        "            inputs = inputs + torch.randn_like(inputs) * aug_noise_std\n",
        "        \n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "            logits = model(inputs)\n",
        "            loss = criterion(logits, targets)\n",
        "            if l1_lambda > 0:\n",
        "                loss = loss + l1_lambda * sum(p.abs().sum() for p in model.parameters())\n",
        "            if l2_lambda > 0:\n",
        "                loss = loss + l2_lambda * sum(p.pow(2).sum() for p in model.parameters())\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        all_predictions.append(preds.cpu().numpy())\n",
        "        all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    epoch_f1 = f1_score(np.concatenate(all_targets), np.concatenate(all_predictions), average=\"weighted\")\n",
        "    return epoch_loss, epoch_f1\n",
        "\n",
        "\n",
        "def validate_one_epoch(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_predictions, all_targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs, targets = move_batch((inputs, targets))\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "                logits = model(inputs)\n",
        "                loss = criterion(logits, targets)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            all_predictions.append(preds.cpu().numpy())\n",
        "            all_targets.append(targets.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(val_loader.dataset)\n",
        "    epoch_f1 = f1_score(np.concatenate(all_targets), np.concatenate(all_predictions), average=\"weighted\")\n",
        "    return epoch_loss, epoch_f1\n",
        "\n",
        "\n",
        "def log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model, lr=None):\n",
        "    if writer is None:\n",
        "        return\n",
        "    writer.add_scalar(\"Loss/Training\", train_loss, epoch)\n",
        "    writer.add_scalar(\"Loss/Validation\", val_loss, epoch)\n",
        "    writer.add_scalar(\"F1/Training\", train_f1, epoch)\n",
        "    writer.add_scalar(\"F1/Validation\", val_f1, epoch)\n",
        "    if lr is not None:\n",
        "        writer.add_scalar(\"LearningRate\", lr, epoch)\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad and param.numel() > 0:\n",
        "            writer.add_histogram(f\"{name}/weights\", param.data, epoch)\n",
        "            if param.grad is not None and param.grad.numel() > 0 and torch.isfinite(param.grad).all():\n",
        "                writer.add_histogram(f\"{name}/gradients\", param.grad.data, epoch)\n",
        "\n",
        "\n",
        "def fit(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    epochs,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    scaler,\n",
        "    device,\n",
        "    scheduler=None,\n",
        "    l1_lambda=0.0,\n",
        "    l2_lambda=0.0,\n",
        "    patience=0,\n",
        "    evaluation_metric=\"val_f1\",\n",
        "    mode=\"max\",\n",
        "    restore_best_weights=True,\n",
        "    writer=None,\n",
        "    verbose=10,\n",
        "    experiment_name=\"\",\n",
        "):\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"train_f1\": [], \"val_f1\": []}\n",
        "    best_metric = float(\"-inf\") if mode == \"max\" else float(\"inf\")\n",
        "    best_state = None\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss, train_f1 = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, scaler, device, \n",
        "            l1_lambda=l1_lambda, l2_lambda=l2_lambda,\n",
        "            use_augmentation=USE_TRAIN_AUGMENTATION, aug_noise_std=TRAIN_AUG_NOISE_STD\n",
        "        )\n",
        "        val_loss, val_f1 = validate_one_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_f1\"].append(train_f1)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_f1\"].append(val_f1)\n",
        "\n",
        "        current_metric = history[evaluation_metric][-1]\n",
        "        improved = current_metric > best_metric if mode == \"max\" else current_metric < best_metric\n",
        "        if improved:\n",
        "            best_metric = current_metric\n",
        "            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "            epochs_without_improvement = 0\n",
        "            if writer is not None and experiment_name:\n",
        "                os.makedirs(Path(\"models\") / experiment_name, exist_ok=True)\n",
        "                # Save best model with metadata\n",
        "                checkpoint_data = {\n",
        "                    'state_dict': model.state_dict(),\n",
        "                    'epoch': epoch,\n",
        "                    'val_f1': val_f1,\n",
        "                    'val_loss': val_loss,\n",
        "                }\n",
        "                torch.save(checkpoint_data, Path(\"models\") / experiment_name / f\"{experiment_name}_best.pt\")\n",
        "                # Also save periodic checkpoints for ensemble\n",
        "                if epoch % 30 == 0 or epoch <= 10:  # Save more frequently\n",
        "                    checkpoint_data = {\n",
        "                        'state_dict': model.state_dict(),\n",
        "                        'epoch': epoch,\n",
        "                        'val_f1': val_f1,\n",
        "                        'val_loss': val_loss,\n",
        "                    }\n",
        "                    torch.save(checkpoint_data, Path(\"models\") / experiment_name / f\"{experiment_name}_epoch_{epoch}.pt\")\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        if scheduler is not None:\n",
        "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                scheduler.step(val_loss)\n",
        "            else:\n",
        "                # CosineAnnealingWarmRestarts and other schedulers step every epoch\n",
        "                scheduler.step()\n",
        "            current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "        else:\n",
        "            current_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        if verbose and (epoch % verbose == 0 or epoch == 1):\n",
        "            print(\n",
        "                f\"Epoch {epoch:03d}/{epochs} | \"\n",
        "                f\"Train: Loss={train_loss:.4f}, F1={train_f1:.4f} | \"\n",
        "                f\"Val: Loss={val_loss:.4f}, F1={val_f1:.4f} | \"\n",
        "                f\"LR={current_lr:.2e}\"\n",
        "            )\n",
        "\n",
        "        log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model, lr=current_lr)\n",
        "\n",
        "        if patience and epochs_without_improvement >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch} epochs.\")\n",
        "            break\n",
        "\n",
        "    if restore_best_weights and best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    if writer is not None:\n",
        "        writer.close()\n",
        "\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimized Hyperparameters\n",
        "\n",
        "Key optimizations for achieving >96% accuracy:\n",
        "- **Bidirectional GRU**: Captures temporal patterns in both forward and backward directions\n",
        "- **Deeper network**: 3 layers with 128 hidden units per layer\n",
        "- **Class weights + label smoothing**: Handles imbalanced classes effectively\n",
        "- **Learning rate scheduling**: Adaptive LR reduction on plateau\n",
        "- **Tuned regularization**: Dropout and L2 weight decay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimized hyperparameters for >96% accuracy\n",
        "LEARNING_RATE = 1e-3  # Start with higher LR, scheduler will reduce it\n",
        "EPOCHS = 500\n",
        "PATIENCE = 50\n",
        "\n",
        "# Architecture - deeper and wider for better capacity\n",
        "HIDDEN_LAYERS = 3        # 3 layers for better representation learning\n",
        "HIDDEN_SIZE = 160        # Increased from 128 for more capacity\n",
        "BIDIRECTIONAL = True     # Critical: bidirectional captures both temporal directions\n",
        "\n",
        "# Regularisation\n",
        "DROPOUT_RATE = 0.25      # Slightly increased dropout\n",
        "L1_LAMBDA = 0.0          # L1 not needed with L2\n",
        "L2_LAMBDA = 1e-4         # L2 weight decay for regularization\n",
        "\n",
        "# Loss function options - MORE AGGRESSIVE for minority classes\n",
        "USE_FOCAL_LOSS = True    # Use Focal Loss for better minority class handling\n",
        "FOCAL_GAMMA = 2.5        # Increased from 2.0 - more focus on hard examples\n",
        "LABEL_SMOOTHING = 0.05   # Reduced from 0.1 to give more confidence to minority classes\n",
        "\n",
        "# Training augmentation\n",
        "USE_TRAIN_AUGMENTATION = True  # Add noise during training for better generalization\n",
        "TRAIN_AUG_NOISE_STD = 0.005    # Smaller noise during training\n",
        "\n",
        "# Inference options\n",
        "USE_TTA = True           # Test-Time Augmentation: average predictions with noise\n",
        "TTA_NUM_AUGS = 5         # Number of augmented versions per sample\n",
        "TTA_NOISE_STD = 0.01     # Standard deviation of Gaussian noise for TTA\n",
        "ENSEMBLE_CHECKPOINTS = True  # Ensemble multiple best checkpoints\n",
        "NUM_ENSEMBLE_MODELS = 5  # Increased: more models for ensemble\n",
        "USE_WEIGHTED_ENSEMBLE = True  # Weight models by validation performance\n",
        "USE_ATTENTION = True     # Use attention mechanism in model\n",
        "\n",
        "logs_dir = \"tensorboard\"\n",
        "os.makedirs(logs_dir, exist_ok=True)\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "# Set up loss function: Focal Loss or Weighted CrossEntropy with label smoothing\n",
        "if USE_FOCAL_LOSS:\n",
        "    criterion = FocalLoss(alpha=class_weights, gamma=FOCAL_GAMMA)\n",
        "    print(f\"Loss function: Focal Loss (gamma={FOCAL_GAMMA}) with class weights\")\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=LABEL_SMOOTHING)\n",
        "    print(f\"Loss function: CrossEntropyLoss with class weights and label_smoothing={LABEL_SMOOTHING}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create bidirectional GRU model with attention\n",
        "model = RecurrentClassifier(\n",
        "    input_size=input_size,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    num_layers=HIDDEN_LAYERS,\n",
        "    num_classes=num_classes,\n",
        "    rnn_type=\"GRU\",\n",
        "    bidirectional=BIDIRECTIONAL,\n",
        "    dropout_rate=DROPOUT_RATE,\n",
        "    use_attention=USE_ATTENTION,\n",
        ").to(device)\n",
        "\n",
        "recurrent_summary(model, input_shape)\n",
        "\n",
        "# Set up TensorBoard logging\n",
        "experiment_name = \"gru_optimized\"\n",
        "writer = SummaryWriter(Path(logs_dir) / experiment_name)\n",
        "\n",
        "# Log model graph\n",
        "x_dummy = torch.randn(1, *input_shape).to(device)\n",
        "writer.add_graph(model, x_dummy)\n",
        "\n",
        "# Optimizer with L2 regularization\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
        "\n",
        "# Learning rate scheduler: Cosine annealing with warm restarts for better convergence\n",
        "# This provides more aggressive LR decay and helps escape local minima\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=30, T_mult=2, eta_min=1e-6\n",
        ")\n",
        "# Alternative: ReduceLROnPlateau (uncomment to use instead)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "#     optimizer, mode='min', factor=0.5, patience=15, min_lr=1e-6\n",
        "# )\n",
        "\n",
        "# Mixed precision training scaler\n",
        "scaler = torch.amp.GradScaler(enabled=(device.type == \"cuda\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the optimized GRU model\n",
        "model, history = fit(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    epochs=EPOCHS,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scaler=scaler,\n",
        "    device=device,\n",
        "    scheduler=scheduler,\n",
        "    l1_lambda=L1_LAMBDA,\n",
        "    l2_lambda=L2_LAMBDA,\n",
        "    patience=PATIENCE,\n",
        "    writer=writer,\n",
        "    verbose=1,\n",
        "    experiment_name=experiment_name,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "epochs_ran = len(history['train_loss'])\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
        "axes[0].plot(range(1, epochs_ran + 1), history['train_loss'], label='Train', alpha=0.7)\n",
        "axes[0].plot(range(1, epochs_ran + 1), history['val_loss'], label='Validation', alpha=0.9)\n",
        "axes[0].set_title('Loss')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].plot(range(1, epochs_ran + 1), history['train_f1'], label='Train F1', alpha=0.7)\n",
        "axes[1].plot(range(1, epochs_ran + 1), history['val_f1'], label='Validation F1', alpha=0.9)\n",
        "axes[1].set_title('Weighted F1 Score')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('F1 Score')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Best validation F1: {max(history['val_f1']):.4f}\")\n",
        "print(f\"Best validation F1 at epoch: {np.argmax(history['val_f1']) + 1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed validation performance analysis\n",
        "val_loss, val_f1 = validate_one_epoch(model, val_loader, criterion, device)\n",
        "print(f\"Validation loss: {val_loss:.4f}\")\n",
        "print(f\"Validation weighted F1: {val_f1:.4f}\")\n",
        "\n",
        "val_preds, val_targets = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in val_loader:\n",
        "        xb, yb = move_batch((xb, yb))\n",
        "        logits = model(xb)\n",
        "        val_preds.append(logits.argmax(dim=1).cpu().numpy())\n",
        "        val_targets.append(yb.cpu().numpy())\n",
        "\n",
        "val_preds = np.concatenate(val_preds)\n",
        "val_targets = np.concatenate(val_targets)\n",
        "val_accuracy = accuracy_score(val_targets, val_preds)\n",
        "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# Per-class metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(val_targets, val_preds, target_names=[idx_to_label[i] for i in range(num_classes)]))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(val_targets, val_preds)\n",
        "cm_df = pd.DataFrame(cm, index=[idx_to_label[i] for i in range(num_classes)], \n",
        "                      columns=[idx_to_label[i] for i in range(num_classes)])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Count'})\n",
        "plt.title('Validation Confusion Matrix')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on the held-out test set (standard evaluation)\n",
        "test_loss, test_f1 = validate_one_epoch(model, test_loader, criterion, device)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test weighted F1: {test_f1:.4f}\")\n",
        "\n",
        "test_preds, test_targets = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb, yb = move_batch((xb, yb))\n",
        "        logits = model(xb)\n",
        "        test_preds.append(logits.argmax(dim=1).cpu().numpy())\n",
        "        test_targets.append(yb.cpu().numpy())\n",
        "\n",
        "test_preds = np.concatenate(test_preds)\n",
        "test_targets = np.concatenate(test_targets)\n",
        "test_accuracy = accuracy_score(test_targets, test_preds)\n",
        "print(f\"Test accuracy (standard): {test_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nTest Set Classification Report (standard):\")\n",
        "print(classification_report(test_targets, test_preds, target_names=[idx_to_label[i] for i in range(num_classes)]))\n",
        "\n",
        "# Evaluate with Test-Time Augmentation for comparison\n",
        "if USE_TTA:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Evaluating with Test-Time Augmentation...\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    test_preds_tta = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_loader:\n",
        "            xb, yb = move_batch((xb, yb))\n",
        "            # Use TTA\n",
        "            all_probs = []\n",
        "            logits = model(xb)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            all_probs.append(probs.cpu().numpy())\n",
        "            \n",
        "            for _ in range(TTA_NUM_AUGS - 1):\n",
        "                xb_aug = xb + torch.randn_like(xb) * TTA_NOISE_STD\n",
        "                logits_aug = model(xb_aug)\n",
        "                probs_aug = torch.softmax(logits_aug, dim=1)\n",
        "                all_probs.append(probs_aug.cpu().numpy())\n",
        "            \n",
        "            avg_probs = np.mean(all_probs, axis=0)\n",
        "            test_preds_tta.append(np.argmax(avg_probs, axis=1))\n",
        "    \n",
        "    test_preds_tta = np.concatenate(test_preds_tta)\n",
        "    test_accuracy_tta = accuracy_score(test_targets, test_preds_tta)\n",
        "    test_f1_tta = f1_score(test_targets, test_preds_tta, average=\"weighted\")\n",
        "    \n",
        "    print(f\"Test accuracy (with TTA): {test_accuracy_tta:.4f} (improvement: +{test_accuracy_tta - test_accuracy:.4f})\")\n",
        "    print(f\"Test weighted F1 (with TTA): {test_f1_tta:.4f} (improvement: +{test_f1_tta - test_f1:.4f})\")\n",
        "    \n",
        "    print(\"\\nTest Set Classification Report (with TTA):\")\n",
        "    print(classification_report(test_targets, test_preds_tta, target_names=[idx_to_label[i] for i in range(num_classes)]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build Kaggle submission predictions with Test-Time Augmentation and Ensemble\n",
        "# This combines multiple techniques for maximum accuracy\n",
        "submission = sample_submission.copy()\n",
        "if inference_loader is None or inference_window_ids is None:\n",
        "    print(\"Inference tensors are not available in the bundle; skipping submission build.\")\n",
        "else:\n",
        "    def predict_with_tta(model, xb, num_augs=TTA_NUM_AUGS, noise_std=TTA_NOISE_STD):\n",
        "        \"\"\"Predict with test-time augmentation by adding noise and averaging.\"\"\"\n",
        "        model.eval()\n",
        "        all_probs = []\n",
        "        with torch.no_grad():\n",
        "            # Original prediction\n",
        "            logits = model(xb)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            all_probs.append(probs.cpu().numpy())\n",
        "            \n",
        "            # Augmented predictions\n",
        "            for _ in range(num_augs - 1):\n",
        "                xb_aug = xb + torch.randn_like(xb) * noise_std\n",
        "                logits_aug = model(xb_aug)\n",
        "                probs_aug = torch.softmax(logits_aug, dim=1)\n",
        "                all_probs.append(probs_aug.cpu().numpy())\n",
        "        \n",
        "        # Average all predictions\n",
        "        return np.mean(all_probs, axis=0)\n",
        "    \n",
        "    # Load ensemble models if available\n",
        "    ensemble_models = []\n",
        "    model_weights = []\n",
        "    if ENSEMBLE_CHECKPOINTS:\n",
        "        model_dir = Path(\"models\") / experiment_name\n",
        "        if model_dir.exists():\n",
        "            checkpoint_files = sorted(model_dir.glob(f\"{experiment_name}_epoch_*.pt\"))\n",
        "            # Get top N checkpoints by validation performance\n",
        "            if checkpoint_files:\n",
        "                # Load all checkpoints and get their validation F1 scores\n",
        "                checkpoint_scores = []\n",
        "                best_model_path = model_dir / f\"{experiment_name}_best.pt\"\n",
        "                if best_model_path.exists():\n",
        "                    try:\n",
        "                        ckpt = torch.load(best_model_path, map_location=\"cpu\")\n",
        "                        if isinstance(ckpt, dict) and 'val_f1' in ckpt:\n",
        "                            checkpoint_scores.append((best_model_path, ckpt['val_f1']))\n",
        "                        else:\n",
        "                            checkpoint_scores.append((best_model_path, 1.0))  # Default weight for best\n",
        "                    except:\n",
        "                        checkpoint_scores.append((best_model_path, 1.0))\n",
        "                \n",
        "                # Load epoch checkpoints\n",
        "                for ckpt_path in checkpoint_files:\n",
        "                    try:\n",
        "                        ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "                        if isinstance(ckpt, dict) and 'val_f1' in ckpt:\n",
        "                            checkpoint_scores.append((ckpt_path, ckpt['val_f1']))\n",
        "                    except:\n",
        "                        pass\n",
        "                \n",
        "                # Sort by validation F1 and take top N\n",
        "                checkpoint_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "                top_checkpoints = checkpoint_scores[:NUM_ENSEMBLE_MODELS]\n",
        "                \n",
        "                ensemble_models = [ckpt[0] for ckpt in top_checkpoints]\n",
        "                if USE_WEIGHTED_ENSEMBLE:\n",
        "                    # Weight by validation F1 score\n",
        "                    scores = np.array([ckpt[1] for ckpt in top_checkpoints])\n",
        "                    model_weights = scores / scores.sum()  # Normalize\n",
        "                else:\n",
        "                    model_weights = np.ones(len(ensemble_models)) / len(ensemble_models)\n",
        "                \n",
        "                print(f\"Found {len(ensemble_models)} models for ensemble:\")\n",
        "                for i, (ckpt_path, score) in enumerate(top_checkpoints):\n",
        "                    weight_str = f\" (weight={model_weights[i]:.3f})\" if USE_WEIGHTED_ENSEMBLE else \"\"\n",
        "                    print(f\"  {i+1}. {ckpt_path.name}: val_f1={score:.4f}{weight_str}\")\n",
        "    \n",
        "    # Collect predictions from all models (with TTA if enabled)\n",
        "    all_window_probs = []\n",
        "    \n",
        "    models_to_use = ensemble_models if ensemble_models else [None]  # None means use current model\n",
        "    weights_to_use = model_weights if model_weights else [1.0]\n",
        "    \n",
        "    for model_idx, model_path in enumerate(models_to_use):\n",
        "        if model_path is not None:\n",
        "            # Load checkpoint\n",
        "            temp_model = RecurrentClassifier(\n",
        "                input_size=input_size,\n",
        "                hidden_size=HIDDEN_SIZE,\n",
        "                num_layers=HIDDEN_LAYERS,\n",
        "                num_classes=num_classes,\n",
        "                rnn_type=\"GRU\",\n",
        "                bidirectional=BIDIRECTIONAL,\n",
        "                dropout_rate=DROPOUT_RATE,\n",
        "                use_attention=USE_ATTENTION,\n",
        "            ).to(device)\n",
        "            ckpt = torch.load(model_path, map_location=device)\n",
        "            if isinstance(ckpt, dict):\n",
        "                temp_model.load_state_dict(ckpt['state_dict'])\n",
        "            else:\n",
        "                temp_model.load_state_dict(ckpt)\n",
        "            temp_model.eval()\n",
        "            current_model = temp_model\n",
        "            print(f\"Using ensemble model {model_idx + 1}/{len(models_to_use)}: {model_path.name}\")\n",
        "        else:\n",
        "            current_model = model\n",
        "            print(f\"Using current model\")\n",
        "        \n",
        "        window_probs_list = []\n",
        "        with torch.no_grad():\n",
        "            for (xb,) in inference_loader:\n",
        "                xb = xb.to(device)\n",
        "                if USE_TTA:\n",
        "                    probs = predict_with_tta(current_model, xb, TTA_NUM_AUGS, TTA_NOISE_STD)\n",
        "                else:\n",
        "                    logits = current_model(xb)\n",
        "                    probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "                window_probs_list.append(probs)\n",
        "        \n",
        "        window_probs = np.concatenate(window_probs_list, axis=0)\n",
        "        all_window_probs.append(window_probs)\n",
        "    \n",
        "    # Ensemble: weighted average probabilities across all models\n",
        "    if len(all_window_probs) > 1:\n",
        "        print(f\"Ensembling {len(all_window_probs)} models (weighted={USE_WEIGHTED_ENSEMBLE})...\")\n",
        "        if USE_WEIGHTED_ENSEMBLE and len(weights_to_use) == len(all_window_probs):\n",
        "            # Weighted ensemble\n",
        "            ensemble_probs = np.zeros_like(all_window_probs[0])\n",
        "            for probs, weight in zip(all_window_probs, weights_to_use):\n",
        "                ensemble_probs += probs * weight\n",
        "        else:\n",
        "            # Simple average\n",
        "            ensemble_probs = np.mean(all_window_probs, axis=0)\n",
        "    else:\n",
        "        ensemble_probs = all_window_probs[0]\n",
        "    \n",
        "    if len(ensemble_probs) != len(inference_window_ids):\n",
        "        raise ValueError(\"Mismatch between inference predictions and window id list length.\")\n",
        "\n",
        "    # Aggregate predictions: weighted voting by confidence scores\n",
        "    agg_probs: Dict[str, np.ndarray] = {}\n",
        "    for sid, prob_vec in zip(inference_window_ids, ensemble_probs):\n",
        "        if sid not in agg_probs:\n",
        "            agg_probs[sid] = []\n",
        "        agg_probs[sid].append(prob_vec)\n",
        "    \n",
        "    # Average probabilities for each sample, then take argmax\n",
        "    final_predictions = {}\n",
        "    default_label_idx = min(int(k) for k in idx_to_label.keys())\n",
        "    \n",
        "    for sid, prob_list in agg_probs.items():\n",
        "        avg_probs = np.mean(prob_list, axis=0)\n",
        "        final_predictions[sid] = int(np.argmax(avg_probs))\n",
        "\n",
        "    submission['label'] = [\n",
        "        idx_to_label.get(final_predictions.get(sid, default_label_idx), idx_to_label[default_label_idx])\n",
        "        for sid in submission['sample_index']\n",
        "    ]\n",
        "    print(\"\\nSubmission preview:\")\n",
        "    print(submission.head(10))\n",
        "    print(f\"\\nSubmission shape: {submission.shape}\")\n",
        "    print(f\"Label distribution in submission:\")\n",
        "    print(submission['label'].value_counts())\n",
        "    print(f\"\\nInference settings:\")\n",
        "    print(f\"  - Test-Time Augmentation: {USE_TTA} (num_augs={TTA_NUM_AUGS}, noise_std={TTA_NOISE_STD})\")\n",
        "    print(f\"  - Ensemble: {ENSEMBLE_CHECKPOINTS} ({len(ensemble_models)} models)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to export submission file\n",
        "# submission.to_csv(\"gru_optimized_submission.csv\", index=False)\n",
        "# print(\"Saved gru_optimized_submission.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Optimizations Applied (v4 - Targeting 99% Accuracy)\n",
        "\n",
        "1. **Bidirectional GRU**: Captures temporal dependencies in both forward and backward directions, significantly improving pattern recognition.\n",
        "\n",
        "2. **Enhanced Focal Loss + Aggressive Class Weights**: \n",
        "   - **Focal Loss** (gamma=2.5, increased from 2.0) focuses even more on hard examples\n",
        "   - **Sqrt-normalized class weights** provide aggressive weighting for minority classes\n",
        "   - Reduced label smoothing (0.05) gives more confidence to minority class predictions\n",
        "\n",
        "3. **Enhanced Architecture**: \n",
        "   - 3 layers with **160 hidden units** for more capacity\n",
        "   - **Two-layer classifier** with ReLU and dropout for better feature transformation\n",
        "   - Better representation learning for complex patterns\n",
        "\n",
        "4. **Advanced Learning Rate Scheduling**: \n",
        "   - **CosineAnnealingWarmRestarts** provides aggressive LR decay with periodic restarts\n",
        "   - Helps escape local minima and find better solutions\n",
        "\n",
        "5. **Improved Regularization**: \n",
        "   - Dropout (0.25) and L2 weight decay (1e-4) prevent overfitting\n",
        "   - Additional dropout in classifier layers\n",
        "\n",
        "6. **Attention Mechanism**: \n",
        "   - **Self-attention** over all time steps to focus on important moments\n",
        "   - Learns which parts of the sequence are most relevant\n",
        "   - Better than just using the last hidden state\n",
        "   - Critical for reaching 99% accuracy\n",
        "\n",
        "7. **Training Data Augmentation**: \n",
        "   - Adds small Gaussian noise during training\n",
        "   - Improves generalization and robustness\n",
        "   - Different from TTA - applied during training\n",
        "\n",
        "8. **Test-Time Augmentation (TTA)**: \n",
        "   - Adds Gaussian noise to inputs during inference\n",
        "   - Averages predictions across multiple augmented versions\n",
        "   - Typically improves accuracy by 0.5-1% by reducing variance\n",
        "\n",
        "9. **Weighted Model Ensemble**: \n",
        "   - Combines predictions from top N checkpoints (by validation F1)\n",
        "   - **Weighted averaging** based on validation performance\n",
        "   - More sophisticated than simple averaging\n",
        "   - Uses 5 best models instead of 3\n",
        "\n",
        "8. **Weighted Voting for Inference**: \n",
        "   - Uses probability scores instead of simple mode voting\n",
        "   - Averages softmax probabilities across windows for each sample\n",
        "   - More robust aggregation that considers prediction confidence\n",
        "\n",
        "9. **Mixed Precision Training**: Uses FP16 for faster training on GPU while maintaining numerical stability.\n",
        "\n",
        "## Expected Improvements\n",
        "\n",
        "- **Attention mechanism**: +1-2% accuracy (learns which time steps matter)\n",
        "- **Training augmentation**: +0.5-1% accuracy (better generalization)\n",
        "- **TTA**: +0.5-1% accuracy improvement\n",
        "- **Weighted ensemble**: +0.5-1.5% accuracy improvement  \n",
        "- **Combined**: Should push test accuracy to **97-99%**\n",
        "\n",
        "## Optional: Per-Subject Normalization\n",
        "\n",
        "If you want to try per-subject normalization (normalizes each subject independently), rebuild the dataset:\n",
        "\n",
        "```bash\n",
        "python build_dataset_pt.py --data-dir dataset --output dataset.pt \\\n",
        "    --window-size 50 --stride 10 --per-subject-norm\n",
        "```\n",
        "\n",
        "This can help if subjects have different scales/ranges. However, it requires rebuilding the dataset and retraining.\n",
        "\n",
        "These optimizations specifically target the `high_pain` class performance issues and work together to maximize accuracy on validation and test sets.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{"cells":[{"cell_type":"markdown","metadata":{"id":"Q5FyEkTbAdUD"},"source":["# **Artificial Neural Networks and Deep Learning**\n","\n","---\n","\n","## **Lecture 4: Timeseries Classification**\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1URwMSSlsgI716DsPSQVJXhll3vaPgL7v\" width=\"500\"/>"]},{"cell_type":"markdown","metadata":{"id":"1FdqcMXk96rS"},"source":["## üåê **Google Drive Connection**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxUZy3U-fjcm"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/gdrive\")\n","current_dir = \"/gdrive/My\\\\ Drive/[2025-2026]\\\\ AN2DL/Lecture\\\\ 4\"\n","%cd $current_dir"]},{"cell_type":"markdown","metadata":{"id":"zfehjCy896Fd"},"source":["## ‚öôÔ∏è **Libraries Import**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x47Uv8R9Akcl"},"outputs":[],"source":["# Set seed for reproducibility\n","SEED = 42\n","\n","# Import necessary libraries\n","import os\n","\n","# Set environment variables before importing modules\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n","\n","# Suppress warnings\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=Warning)\n","\n","# Import necessary modules\n","import logging\n","import random\n","import numpy as np\n","\n","# Set seeds for random number generators in NumPy and Python\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","# Import PyTorch\n","import torch\n","torch.manual_seed(SEED)\n","from torch import nn\n","# from torchsummary import summary\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import TensorDataset, DataLoader\n","logs_dir = \"tensorboard\"\n","!pkill -f tensorboard\n","%load_ext tensorboard\n","!mkdir -p models\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    torch.cuda.manual_seed_all(SEED)\n","    torch.backends.cudnn.benchmark = True\n","else:\n","    device = torch.device(\"cpu\")\n","\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"Device: {device}\")\n","\n","# Import other libraries\n","import copy\n","import shutil\n","from itertools import product\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Configure plot display settings\n","sns.set(font_scale=1.4)\n","sns.set_style('white')\n","plt.rc('font', size=14)\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"XRK9IPIc-ZEz"},"source":["## ‚è≥ **Data Loading**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0yW6Vy5xCBwO"},"outputs":[],"source":["# Set environment variables for Activity Recognition dataset\n","os.environ[\"DATASET_NAME\"] = \"activities_recognition.txt\"\n","os.environ[\"DATASET_URL\"] = \"1QqyAJndGqPa-pWgyI63SuBAT__GnmL1b\"\n","\n","# Check if Activity Recognition dataset exists and download if not\n","if not os.path.exists(os.environ[\"DATASET_NAME\"]):\n","    print(\"Downloading Activity Recognition dataset...\")\n","    !gdown -q ${DATASET_URL} -O ${DATASET_NAME}\n","    print(\"Activity Recognition dataset downloaded!\")\n","else:\n","    print(\"Activity Recognition dataset already downloaded. Using cached data.\")"]},{"cell_type":"markdown","metadata":{"id":"4paoJv0k9Siw"},"source":["## üîé **Exploration and Data Analysis**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0m6Gn4fkm9S"},"outputs":[],"source":["# Define column names for the dataset\n","column_names = ['user_id', 'activity', 'timestamp', 'x_axis', 'y_axis', 'z_axis']\n","\n","# Read the dataset into a DataFrame with specified column names\n","df = pd.read_csv('activities_recognition.txt', header=None, names=column_names)\n","\n","# Remove rows with any missing values\n","df.dropna(axis=0, how='any', inplace=True)\n","\n","# Print the shape of the DataFrame\n","print(f\"DataFrame shape: {df.shape}\")\n","\n","# Display the first 10 rows of the DataFrame\n","df.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sE14d04MmDau"},"outputs":[],"source":["# Display a concise summary of the DataFrame\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuEOax_iWd0v"},"outputs":[],"source":["# Convert 'x_axis' column to float32 data type\n","df['x_axis'] = df['x_axis'].astype(np.float32)\n","\n","# Convert 'y_axis' column to float32 data type\n","df['y_axis'] = df['y_axis'].astype(np.float32)\n","\n","# Convert 'z_axis' column to float32 data type\n","df['z_axis'] = df['z_axis'].astype(np.float32)\n","\n","# Display updated DataFrame information\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnkn-34lU6eC"},"outputs":[],"source":["# Generate descriptive statistics for numerical columns in the DataFrame\n","df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAprzP2bkm4S"},"outputs":[],"source":["# Visualise the count of timestamps for each activity\n","plt.figure(figsize=(17, 5))\n","sns.countplot(\n","    x='activity',\n","    data=df,\n","    order=df['activity'].value_counts().index,\n","    palette='tab10'\n",")\n","\n","# Set the title of the plot\n","plt.title('Activity Timestamps')\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PrVW4q46km1v"},"outputs":[],"source":["# Count the number of unique users\n","n_users = len(df['user_id'].unique())\n","\n","# Create a custom colour map with distinct colours for each user\n","colors = plt.cm.viridis(np.linspace(0, 1, n_users))\n","\n","# Visualise the count of timestamps for each user\n","plt.figure(figsize=(17, 5))\n","sns.countplot(\n","    x='user_id',\n","    data=df,\n","    palette=colors\n",")\n","\n","# Set the title of the plot\n","plt.title('Per User Timestamps')\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3RMXJQUkmzN"},"outputs":[],"source":["# Define a function to inspect sensor data for a specific activity\n","def inspect_activity(activity, df):\n","    # Filter the DataFrame for the specified activity and limit to 500 rows\n","    data = df[df['activity'] == activity][['x_axis', 'y_axis', 'z_axis']][:500]\n","\n","    # Plot the sensor data for each axis\n","    axis = data.plot(subplots=True, figsize=(17, 9), title=activity)\n","\n","    # Adjust legend position for each subplot\n","    for ax in axis:\n","        ax.legend(loc='lower right')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MaDJQzhQkmwt"},"outputs":[],"source":["# Inspect the sensor data for the activity \"Standing\"\n","inspect_activity(\"Standing\", df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0y7XWqFkmt8"},"outputs":[],"source":["# Inspect the sensor data for the activity \"Upstairs\"\n","inspect_activity(\"Upstairs\", df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RaUH02LAr9R8"},"outputs":[],"source":["# Inspect the sensor data for the activity \"Jogging\"\n","inspect_activity(\"Jogging\", df)"]},{"cell_type":"markdown","metadata":{"id":"QTsqFuL6SpAm"},"source":["## üîÑ **Data Preprocessing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y6R_KBCls6z0"},"outputs":[],"source":["# Identify unique activity executions per user by creating a composite ID\n","df['id'] = df['user_id'].astype('str') + '_' + df['activity'].astype('str')\n","\n","# Print the number of unique activity executions\n","print(f'The dataset is composed of {df[\"id\"].nunique()} different activity executions')\n","\n","# Count the unique IDs for distinct activity executions\n","n_users = len(df['id'].unique())\n","\n","# Create a custom colour map for better distinction of unique IDs\n","colors = plt.cm.turbo(np.linspace(0, 1, n_users))\n","\n","# Visualise the count of timestamps per unique ID\n","plt.figure(figsize=(17, 5))\n","sns.countplot(\n","    x='id',\n","    data=df,\n","    order=df['id'].value_counts().index,\n","    palette=colors\n",")\n","\n","# Set the title of the plot and disable x-axis labels for clarity\n","plt.title('Per Id Timestamps')\n","plt.xticks([], [])  # Remove x-axis ticks and labels\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bYLncaLxyCJO"},"outputs":[],"source":["# Display the first five rows of the DataFrame\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8HtgcBGAzaD"},"outputs":[],"source":["# Get unique user IDs and shuffle them\n","unique_users = df['user_id'].unique()\n","random.seed(SEED) # Ensure reproducibility of shuffling\n","random.shuffle(unique_users)\n","\n","# Define the number of users for validation and test sets\n","N_VAL_USERS = 5 # You can change this number\n","N_TEST_USERS = 5 # You can change this number\n","\n","# Calculate the number of users for the training set\n","n_train_users = len(unique_users) - N_VAL_USERS - N_TEST_USERS\n","\n","# Split the shuffled user IDs into training, validation, and test sets\n","train_users = unique_users[:n_train_users]\n","val_users = unique_users[n_train_users:n_train_users + N_VAL_USERS]\n","test_users = unique_users[n_train_users + N_VAL_USERS:]\n","\n","# Split the dataset into training, validation, and test sets based on user IDs\n","df_train = df[df['user_id'].isin(train_users)]\n","df_val = df[df['user_id'].isin(val_users)]\n","df_test = df[df['user_id'].isin(test_users)]\n","\n","# Print the shapes of the training, validation, and test sets\n","print(f'Training set shape: {df_train.shape}')\n","print(f'Validation set shape: {df_val.shape}')\n","print(f'Test set shape: {df_test.shape}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_f41l7pX_JmC"},"outputs":[],"source":["# Initialise a dictionary to count occurrences of each activity in the training set\n","training_labels = {\n","    'Walking': 0,\n","    'Jogging': 0,\n","    'Upstairs': 0,\n","    'Downstairs': 0,\n","    'Sitting': 0,\n","    'Standing': 0\n","}\n","\n","# Count occurrences of each activity for unique IDs in the training set\n","for id in df_train['id'].unique():\n","    label = df_train[df_train['id'] == id]['activity'].values[0]\n","    training_labels[label] += 1\n","\n","# Print the distribution of training labels\n","print('Training labels:', training_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ed577kr5F8HQ"},"outputs":[],"source":["# Initialise a dictionary to count occurrences of each activity in the validation set\n","val_labels = {\n","    'Walking': 0,\n","    'Jogging': 0,\n","    'Upstairs': 0,\n","    'Downstairs': 0,\n","    'Sitting': 0,\n","    'Standing': 0\n","}\n","\n","# Count occurrences of each activity for unique IDs in the validation set\n","for id in df_val['id'].unique():\n","    label = df_val[df_val['id'] == id]['activity'].values[0]\n","    val_labels[label] += 1\n","\n","# Print the distribution of validation labels\n","print('Validation labels:', val_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2_SOzetAN_V"},"outputs":[],"source":["# Initialise a dictionary to count occurrences of each activity in the test set\n","test_labels = {\n","    'Walking': 0,\n","    'Jogging': 0,\n","    'Upstairs': 0,\n","    'Downstairs': 0,\n","    'Sitting': 0,\n","    'Standing': 0\n","}\n","\n","# Count occurrences of each activity for unique IDs in the test set\n","for id in df_test['id'].unique():\n","    label = df_test[df_test['id'] == id]['activity'].values[0]\n","    test_labels[label] += 1\n","\n","# Print the distribution of test labels\n","print('Test labels:', test_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ec5AFCLqFvd0"},"outputs":[],"source":["# Define a mapping of activity names to integer labels\n","label_mapping = {\n","    'Walking': 0,\n","    'Jogging': 1,\n","    'Upstairs': 2,\n","    'Downstairs': 3,\n","    'Sitting': 4,\n","    'Standing': 5\n","}\n","\n","# Map activity names to integers in the training set\n","df_train['activity'] = df_train['activity'].map(label_mapping)\n","\n","# Map activity names to integers in the validation set\n","df_val['activity'] = df_val['activity'].map(label_mapping)\n","\n","# Map activity names to integers in the test set\n","df_test['activity'] = df_test['activity'].map(label_mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b8YZJJSvAmvJ"},"outputs":[],"source":["# Define the columns to be normalised\n","scale_columns = ['x_axis', 'y_axis', 'z_axis']\n","\n","# Calculate the minimum and maximum values from the training data only\n","mins = df_train[scale_columns].min()\n","maxs = df_train[scale_columns].max()\n","\n","# Apply normalisation to the specified columns in all datasets\n","for column in scale_columns:\n","    # Normalise the training set\n","    df_train[column] = (df_train[column] - mins[column]) / (maxs[column] - mins[column])\n","\n","    # Normalise the validation set\n","    df_val[column] = (df_val[column] - mins[column]) / (maxs[column] - mins[column])\n","\n","    # Normalise the test set\n","    df_test[column] = (df_test[column] - mins[column]) / (maxs[column] - mins[column])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sh4k_B_9CbmF"},"outputs":[],"source":["# Display the first five rows of the training DataFrame\n","print(df_train.shape)\n","df_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQYPViwbwgTk"},"outputs":[],"source":["# Define the window size\n","WINDOW_SIZE = 200\n","\n","# Define the stride for overlapping windows\n","STRIDE = 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xy2VJmHIu6iJ"},"outputs":[],"source":["# Define a function to build sequences from the dataset\n","def build_sequences(df, window=200, stride=200):\n","    # Sanity check to ensure the window is divisible by the stride\n","    assert window % stride == 0\n","\n","    # Initialise lists to store sequences and their corresponding labels\n","    dataset = []\n","    labels = []\n","\n","    # Iterate over unique IDs in the DataFrame\n","    for id in df['id'].unique():\n","        # Extract sensor data for the current ID\n","        temp = df[df['id'] == id][['x_axis', 'y_axis', 'z_axis']].values\n","\n","        # Retrieve the activity label for the current ID\n","        label = df[df['id'] == id]['activity'].values[0]\n","\n","        # Calculate padding length to ensure full windows\n","        padding_len = window - len(temp) % window\n","\n","        # Create zero padding and concatenate with the data\n","        padding = np.zeros((padding_len, 3), dtype='float32')\n","        temp = np.concatenate((temp, padding))\n","\n","        # Build feature windows and associate them with labels\n","        idx = 0\n","        while idx + window <= len(temp):\n","            dataset.append(temp[idx:idx + window])\n","            labels.append(label)\n","            idx += stride\n","\n","    # Convert lists to numpy arrays for further processing\n","    dataset = np.array(dataset)\n","    labels = np.array(labels)\n","\n","    return dataset, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5vs7s2fru6fB"},"outputs":[],"source":["# Generate sequences and labels for the training set\n","X_train, y_train = build_sequences(df_train, WINDOW_SIZE, STRIDE)\n","\n","# Generate sequences and labels for the validation set\n","X_val, y_val = build_sequences(df_val, WINDOW_SIZE, STRIDE)\n","\n","# Generate sequences and labels for the test set\n","X_test, y_test = build_sequences(df_test, WINDOW_SIZE, STRIDE)\n","\n","# Print the shapes of the generated datasets and their labels\n","X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XkUqhy__KMnr"},"outputs":[],"source":["# Define the input shape based on the training data\n","input_shape = X_train.shape[1:]\n","\n","# Define the number of classes based on the categorical labels\n","num_classes = len(np.unique(y_train))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n4g715TtSytf"},"outputs":[],"source":["# Convert numpy arrays to PyTorch datasets (pairs features with labels)\n","train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n","val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n","test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CjhjKSW3WysO"},"outputs":[],"source":["# Define the batch size, which is the number of samples in each batch\n","BATCH_SIZE = 512"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fIkKaZJkW0z_"},"outputs":[],"source":["def make_loader(ds, batch_size, shuffle, drop_last):\n","    # Determine optimal number of worker processes for data loading\n","    cpu_cores = os.cpu_count() or 2\n","    num_workers = max(2, min(4, cpu_cores))\n","\n","    # Create DataLoader with performance optimizations\n","    return DataLoader(\n","        ds,\n","        batch_size=batch_size,\n","        shuffle=shuffle,\n","        drop_last=drop_last,\n","        num_workers=num_workers,\n","        pin_memory=True,  # Faster GPU transfer\n","        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n","        prefetch_factor=4,  # Load 4 batches ahead\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ZR5CG9qW2AI"},"outputs":[],"source":["# Create data loaders with different settings for each phase\n","train_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n","val_loader   = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n","test_loader  = make_loader(test_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPpKL3_NW2dq"},"outputs":[],"source":["# Get one batch from the training data loader\n","for xb, yb in train_loader:\n","    print(\"Features batch shape:\", xb.shape)\n","    print(\"Labels batch shape:\", yb.shape)\n","    break # Stop after getting one batch"]},{"cell_type":"markdown","metadata":{"id":"IfejlDqBYOOM"},"source":["## üõ†Ô∏è **Model Building**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VraH-QTDxHWD"},"outputs":[],"source":["def recurrent_summary(model, input_size):\n","    \"\"\"\n","    Custom summary function that emulates torchinfo's output while correctly\n","    counting parameters for RNN/GRU/LSTM layers.\n","\n","    This function is designed for models whose direct children are\n","    nn.Linear, nn.RNN, nn.GRU, or nn.LSTM layers.\n","\n","    Args:\n","        model (nn.Module): The model to analyze.\n","        input_size (tuple): Shape of the input tensor (e.g., (seq_len, features)).\n","    \"\"\"\n","\n","    # Dictionary to store output shapes captured by forward hooks\n","    output_shapes = {}\n","    # List to track hook handles for later removal\n","    hooks = []\n","\n","    def get_hook(name):\n","        \"\"\"Factory function to create a forward hook for a specific module.\"\"\"\n","        def hook(module, input, output):\n","            # Handle RNN layer outputs (returns a tuple)\n","            if isinstance(output, tuple):\n","                # output[0]: all hidden states with shape (batch, seq_len, hidden*directions)\n","                shape1 = list(output[0].shape)\n","                shape1[0] = -1  # Replace batch dimension with -1\n","\n","                # output[1]: final hidden state h_n (or tuple (h_n, c_n) for LSTM)\n","                if isinstance(output[1], tuple):  # LSTM case: (h_n, c_n)\n","                    shape2 = list(output[1][0].shape)  # Extract h_n only\n","                else:  # RNN/GRU case: h_n only\n","                    shape2 = list(output[1].shape)\n","\n","                # Replace batch dimension (middle position) with -1\n","                shape2[1] = -1\n","\n","                output_shapes[name] = f\"[{shape1}, {shape2}]\"\n","\n","            # Handle standard layer outputs (e.g., Linear)\n","            else:\n","                shape = list(output.shape)\n","                shape[0] = -1  # Replace batch dimension with -1\n","                output_shapes[name] = f\"{shape}\"\n","        return hook\n","\n","    # 1. Determine the device where model parameters reside\n","    try:\n","        device = next(model.parameters()).device\n","    except StopIteration:\n","        device = torch.device(\"cpu\")  # Fallback for models without parameters\n","\n","    # 2. Create a dummy input tensor with batch_size=1\n","    dummy_input = torch.randn(1, *input_size).to(device)\n","\n","    # 3. Register forward hooks on target layers\n","    # Iterate through direct children of the model (e.g., self.rnn, self.classifier)\n","    for name, module in model.named_children():\n","        if isinstance(module, (nn.Linear, nn.RNN, nn.GRU, nn.LSTM)):\n","            # Register the hook and store its handle for cleanup\n","            hook_handle = module.register_forward_hook(get_hook(name))\n","            hooks.append(hook_handle)\n","\n","    # 4. Execute a dummy forward pass in evaluation mode\n","    model.eval()\n","    with torch.no_grad():\n","        try:\n","            model(dummy_input)\n","        except Exception as e:\n","            print(f\"Error during dummy forward pass: {e}\")\n","            # Clean up hooks even if an error occurs\n","            for h in hooks:\n","                h.remove()\n","            return\n","\n","    # 5. Remove all registered hooks\n","    for h in hooks:\n","        h.remove()\n","\n","    # --- 6. Print the summary table ---\n","\n","    print(\"-\" * 79)\n","    # Column headers\n","    print(f\"{'Layer (type)':<25} {'Output Shape':<28} {'Param #':<18}\")\n","    print(\"=\" * 79)\n","\n","    total_params = 0\n","    total_trainable_params = 0\n","\n","    # Iterate through modules again to collect and display parameter information\n","    for name, module in model.named_children():\n","        if name in output_shapes:\n","            # Count total and trainable parameters for this module\n","            module_params = sum(p.numel() for p in module.parameters())\n","            trainable_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n","\n","            total_params += module_params\n","            total_trainable_params += trainable_params\n","\n","            # Format strings for display\n","            layer_name = f\"{name} ({type(module).__name__})\"\n","            output_shape_str = str(output_shapes[name])\n","            params_str = f\"{trainable_params:,}\"\n","\n","            print(f\"{layer_name:<25} {output_shape_str:<28} {params_str:<15}\")\n","\n","    print(\"=\" * 79)\n","    print(f\"Total params: {total_params:,}\")\n","    print(f\"Trainable params: {total_trainable_params:,}\")\n","    print(f\"Non-trainable params: {total_params - total_trainable_params:,}\")\n","    print(\"-\" * 79)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ogXWKej_fl6p"},"outputs":[],"source":["class RecurrentClassifier(nn.Module):\n","    \"\"\"\n","    Generic RNN classifier (RNN, LSTM, GRU).\n","    Uses the last hidden state for classification.\n","    \"\"\"\n","    def __init__(\n","            self,\n","            input_size,\n","            hidden_size,\n","            num_layers,\n","            num_classes,\n","            rnn_type='GRU',        # 'RNN', 'LSTM', or 'GRU'\n","            bidirectional=False,\n","            dropout_rate=0.2\n","            ):\n","        super().__init__()\n","\n","        self.rnn_type = rnn_type\n","        self.num_layers = num_layers\n","        self.hidden_size = hidden_size\n","        self.bidirectional = bidirectional\n","\n","        # Map string name to PyTorch RNN class\n","        rnn_map = {\n","            'RNN': nn.RNN,\n","            'LSTM': nn.LSTM,\n","            'GRU': nn.GRU\n","        }\n","\n","        if rnn_type not in rnn_map:\n","            raise ValueError(\"rnn_type must be 'RNN', 'LSTM', or 'GRU'\")\n","\n","        rnn_module = rnn_map[rnn_type]\n","\n","        # Dropout is only applied between layers (if num_layers > 1)\n","        dropout_val = dropout_rate if num_layers > 1 else 0\n","\n","        # Create the recurrent layer\n","        self.rnn = rnn_module(\n","            input_size=input_size,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            batch_first=True,       # Input shape: (batch, seq_len, features)\n","            bidirectional=bidirectional,\n","            dropout=dropout_val\n","        )\n","\n","        # Calculate input size for the final classifier\n","        if self.bidirectional:\n","            classifier_input_size = hidden_size * 2 # Concat fwd + bwd\n","        else:\n","            classifier_input_size = hidden_size\n","\n","        # Final classification layer\n","        self.classifier = nn.Linear(classifier_input_size, num_classes)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x shape: (batch_size, seq_length, input_size)\n","        \"\"\"\n","\n","        # rnn_out shape: (batch_size, seq_len, hidden_size * num_directions)\n","        rnn_out, hidden = self.rnn(x)\n","\n","        # LSTM returns (h_n, c_n), we only need h_n\n","        if self.rnn_type == 'LSTM':\n","            hidden = hidden[0]\n","\n","        # hidden shape: (num_layers * num_directions, batch_size, hidden_size)\n","\n","        if self.bidirectional:\n","            # Reshape to (num_layers, 2, batch_size, hidden_size)\n","            hidden = hidden.view(self.num_layers, 2, -1, self.hidden_size)\n","\n","            # Concat last fwd (hidden[-1, 0, ...]) and bwd (hidden[-1, 1, ...])\n","            # Final shape: (batch_size, hidden_size * 2)\n","            hidden_to_classify = torch.cat([hidden[-1, 0, :, :], hidden[-1, 1, :, :]], dim=1)\n","        else:\n","            # Take the last layer's hidden state\n","            # Final shape: (batch_size, hidden_size)\n","            hidden_to_classify = hidden[-1]\n","\n","        # Get logits\n","        logits = self.classifier(hidden_to_classify)\n","        return logits\n","\n","\n","# Create model and display architecture with parameter count\n","rnn_model = RecurrentClassifier(\n","    input_size=input_shape[-1], # Pass the number of features\n","    hidden_size=128,\n","    num_layers=2,\n","    num_classes=num_classes,\n","    dropout_rate=0.,\n","    rnn_type='RNN'\n","    ).to(device)\n","recurrent_summary(rnn_model, input_size=input_shape)"]},{"cell_type":"markdown","metadata":{"id":"BywFq9R9ma8K"},"source":["## üßÆ **Network and Training Hyperparameters**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HxtAqB60mcAd"},"outputs":[],"source":["# Training configuration\n","LEARNING_RATE = 1e-3\n","EPOCHS = 500\n","PATIENCE = 50\n","\n","# Architecture\n","HIDDEN_LAYERS = 2        # Hidden layers\n","HIDDEN_SIZE = 128        # Neurons per layer\n","\n","# Regularisation\n","DROPOUT_RATE = 0.2         # Dropout probability\n","L1_LAMBDA = 0            # L1 penalty\n","L2_LAMBDA = 0            # L2 penalty\n","\n","# Set up loss function and optimizer\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{"id":"Agr5qySeoI5B"},"source":["## üß† **Model Training**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QxUcNEn7oJ9-"},"outputs":[],"source":["# Initialize best model tracking variables\n","best_model = None\n","best_performance = float('-inf')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3TgsfOzoMeW"},"outputs":[],"source":["def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n","    \"\"\"\n","    Perform one complete training epoch through the entire training dataset.\n","\n","    Args:\n","        model (nn.Module): The neural network model to train\n","        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n","        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n","        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n","        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n","        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n","        l1_lambda (float): Lambda for L1 regularization\n","        l2_lambda (float): Lambda for L2 regularization\n","\n","    Returns:\n","        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n","    \"\"\"\n","    model.train()  # Set model to training mode\n","\n","    running_loss = 0.0\n","    all_predictions = []\n","    all_targets = []\n","\n","    # Iterate through training batches\n","    for batch_idx, (inputs, targets) in enumerate(train_loader):\n","        # Move data to device (GPU/CPU)\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        # Clear gradients from previous step\n","        optimizer.zero_grad(set_to_none=True)\n","\n","        # Forward pass with mixed precision (if CUDA available)\n","        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n","            logits = model(inputs)\n","            loss = criterion(logits, targets)\n","\n","            # Add L1 and L2 regularization\n","            l1_norm = sum(p.abs().sum() for p in model.parameters())\n","            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n","            loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n","\n","\n","        # Backward pass with gradient scaling\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        # Accumulate metrics\n","        running_loss += loss.item() * inputs.size(0)\n","        predictions = logits.argmax(dim=1)\n","        all_predictions.append(predictions.cpu().numpy())\n","        all_targets.append(targets.cpu().numpy())\n","\n","    # Calculate epoch metrics\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    epoch_f1 = f1_score(\n","        np.concatenate(all_targets),\n","        np.concatenate(all_predictions),\n","        average='weighted'\n","    )\n","\n","    return epoch_loss, epoch_f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iR7Oa-m4oOm2"},"outputs":[],"source":["def validate_one_epoch(model, val_loader, criterion, device):\n","    \"\"\"\n","    Perform one complete validation epoch through the entire validation dataset.\n","\n","    Args:\n","        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n","        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n","        criterion (nn.Module): Loss function used to calculate validation loss\n","        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n","\n","    Returns:\n","        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n","\n","    Note:\n","        This function automatically sets the model to evaluation mode and disables\n","        gradient computation for efficiency during validation.\n","    \"\"\"\n","    model.eval()  # Set model to evaluation mode\n","\n","    running_loss = 0.0\n","    all_predictions = []\n","    all_targets = []\n","\n","    # Disable gradient computation for validation\n","    with torch.no_grad():\n","        for inputs, targets in val_loader:\n","            # Move data to device\n","            inputs, targets = inputs.to(device), targets.to(device)\n","\n","            # Forward pass with mixed precision (if CUDA available)\n","            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n","                logits = model(inputs)\n","                loss = criterion(logits, targets)\n","\n","            # Accumulate metrics\n","            running_loss += loss.item() * inputs.size(0)\n","            predictions = logits.argmax(dim=1)\n","            all_predictions.append(predictions.cpu().numpy())\n","            all_targets.append(targets.cpu().numpy())\n","\n","    # Calculate epoch metrics\n","    epoch_loss = running_loss / len(val_loader.dataset)\n","    epoch_accuracy = f1_score(\n","        np.concatenate(all_targets),\n","        np.concatenate(all_predictions),\n","        average='weighted'\n","    )\n","\n","    return epoch_loss, epoch_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ujrKlgKoQ3s"},"outputs":[],"source":["def log_metrics_to_tensorboard(writer, epoch, train_loss, train_f1, val_loss, val_f1, model):\n","    \"\"\"\n","    Log training metrics and model parameters to TensorBoard for visualization.\n","\n","    Args:\n","        writer (SummaryWriter): TensorBoard SummaryWriter object for logging\n","        epoch (int): Current epoch number (used as x-axis in TensorBoard plots)\n","        train_loss (float): Training loss for this epoch\n","        train_f1 (float): Training f1 score for this epoch\n","        val_loss (float): Validation loss for this epoch\n","        val_f1 (float): Validation f1 score for this epoch\n","        model (nn.Module): The neural network model (for logging weights/gradients)\n","\n","    Note:\n","        This function logs scalar metrics (loss/f1 score) and histograms of model\n","        parameters and gradients, which helps monitor training progress and detect\n","        issues like vanishing/exploding gradients.\n","    \"\"\"\n","    # Log scalar metrics\n","    writer.add_scalar('Loss/Training', train_loss, epoch)\n","    writer.add_scalar('Loss/Validation', val_loss, epoch)\n","    writer.add_scalar('F1/Training', train_f1, epoch)\n","    writer.add_scalar('F1/Validation', val_f1, epoch)\n","\n","    # Log model parameters and gradients\n","    for name, param in model.named_parameters():\n","        if param.requires_grad:\n","            # Check if the tensor is not empty before adding a histogram\n","            if param.numel() > 0:\n","                writer.add_histogram(f'{name}/weights', param.data, epoch)\n","            if param.grad is not None:\n","                # Check if the gradient tensor is not empty before adding a histogram\n","                if param.grad.numel() > 0:\n","                    if param.grad is not None and torch.isfinite(param.grad).all():\n","                        writer.add_histogram(f'{name}/gradients', param.grad.data, epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YRCpArKIoS2C"},"outputs":[],"source":["def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n","        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n","        restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\"):\n","    \"\"\"\n","    Train the neural network model on the training data and validate on the validation data.\n","\n","    Args:\n","        model (nn.Module): The neural network model to train\n","        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n","        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n","        epochs (int): Number of training epochs\n","        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n","        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n","        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n","        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n","        l1_lambda (float): L1 regularization coefficient (default: 0)\n","        l2_lambda (float): L2 regularization coefficient (default: 0)\n","        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n","        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n","        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n","        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n","        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n","        verbose (int, optional): Frequency of printing training progress (default: 10)\n","        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n","\n","    Returns:\n","        tuple: (model, training_history) - Trained model and metrics history\n","    \"\"\"\n","\n","    # Initialize metrics tracking\n","    training_history = {\n","        'train_loss': [], 'val_loss': [],\n","        'train_f1': [], 'val_f1': []\n","    }\n","\n","    # Configure early stopping if patience is set\n","    if patience > 0:\n","        patience_counter = 0\n","        best_metric = float('-inf') if mode == 'max' else float('inf')\n","        best_epoch = 0\n","\n","    print(f\"Training {epochs} epochs...\")\n","\n","    # Main training loop: iterate through epochs\n","    for epoch in range(1, epochs + 1):\n","\n","        # Forward pass through training data, compute gradients, update weights\n","        train_loss, train_f1 = train_one_epoch(\n","            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n","        )\n","\n","        # Evaluate model on validation data without updating weights\n","        val_loss, val_f1 = validate_one_epoch(\n","            model, val_loader, criterion, device\n","        )\n","\n","        # Store metrics for plotting and analysis\n","        training_history['train_loss'].append(train_loss)\n","        training_history['val_loss'].append(val_loss)\n","        training_history['train_f1'].append(train_f1)\n","        training_history['val_f1'].append(val_f1)\n","\n","        # Write metrics to TensorBoard for visualization\n","        if writer is not None:\n","            log_metrics_to_tensorboard(\n","                writer, epoch, train_loss, train_f1, val_loss, val_f1, model\n","            )\n","\n","        # Print progress every N epochs or on first epoch\n","        if verbose > 0:\n","            if epoch % verbose == 0 or epoch == 1:\n","                print(f\"Epoch {epoch:3d}/{epochs} | \"\n","                    f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n","                    f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n","\n","        # Early stopping logic: monitor metric and save best model\n","        if patience > 0:\n","            current_metric = training_history[evaluation_metric][-1]\n","            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n","\n","            if is_improvement:\n","                best_metric = current_metric\n","                best_epoch = epoch\n","                torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","                if patience_counter >= patience:\n","                    print(f\"Early stopping triggered after {epoch} epochs.\")\n","                    break\n","\n","    # Restore best model weights if early stopping was used\n","    if restore_best_weights and patience > 0:\n","        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n","        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n","\n","    # Save final model if no early stopping\n","    if patience == 0:\n","        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n","\n","    # Close TensorBoard writer\n","    if writer is not None:\n","        writer.close()\n","\n","    return model, training_history"]},{"cell_type":"markdown","metadata":{"id":"wqL2PdWHdmGC"},"source":["### **Recurrent Neural Network (RNN)**\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=15lVxI3bwelzoFkeC0g4OJsAsH1nedJx4\" width=\"800\"/>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nlcIAz70dt87"},"outputs":[],"source":["# Create model and display architecture with parameter count\n","rnn_model = RecurrentClassifier(\n","    input_size=input_shape[-1], # Pass the number of features\n","    hidden_size=HIDDEN_SIZE,\n","    num_layers=HIDDEN_LAYERS,\n","    num_classes=num_classes,\n","    dropout_rate=DROPOUT_RATE,\n","    bidirectional=False,\n","    rnn_type='RNN'\n","    ).to(device)\n","recurrent_summary(rnn_model, input_size=input_shape)\n","\n","# Set up TensorBoard logging and save model architecture\n","experiment_name = \"rnn\"\n","writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n","x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n","writer.add_graph(rnn_model, x)\n","\n","# Define optimizer with L2 regularization\n","optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n","\n","# Enable mixed precision training for GPU acceleration\n","scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDLP0xlEoUNX"},"outputs":[],"source":["%%time\n","# Train model and track training history\n","rnn_model, training_history = fit(\n","    model=rnn_model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    epochs=EPOCHS,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    scaler=scaler,\n","    device=device,\n","    writer=writer,\n","    verbose=1,\n","    experiment_name=\"rnn\",\n","    patience=PATIENCE\n","    )\n","\n","# Update best model if current performance is superior\n","if training_history['val_f1'][-1] > best_performance:\n","    best_model = rnn_model\n","    best_performance = training_history['val_f1'][-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"_d6Nm475L3MB"},"outputs":[],"source":["# @title Plot Hitory\n","# Create a figure with two side-by-side subplots (two columns)\n","fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n","\n","# Plot of training and validation loss on the first axis\n","ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n","ax1.set_title('Loss')\n","ax1.legend()\n","ax1.grid(alpha=0.3)\n","\n","# Plot of training and validation accuracy on the second axis\n","ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n","ax2.set_title('F1 Score')\n","ax2.legend()\n","ax2.grid(alpha=0.3)\n","\n","# Adjust the layout and display the plot\n","plt.tight_layout()\n","plt.subplots_adjust(right=0.85)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"2pvzW_GHe1Wf"},"outputs":[],"source":["# @title Plot Confusion Matrix\n","# Collect predictions and ground truth labels\n","val_preds, val_targets = [], []\n","with torch.no_grad():  # Disable gradient computation for inference\n","    for xb, yb in val_loader:\n","        xb = xb.to(device)\n","\n","        # Forward pass: get model predictions\n","        logits = rnn_model(xb)\n","        preds = logits.argmax(dim=1).cpu().numpy()\n","\n","        # Store batch results\n","        val_preds.append(preds)\n","        val_targets.append(yb.numpy())\n","\n","# Combine all batches into single arrays\n","val_preds = np.concatenate(val_preds)\n","val_targets = np.concatenate(val_targets)\n","\n","# Calculate overall validation metrics\n","val_acc = accuracy_score(val_targets, val_preds)\n","val_prec = precision_score(val_targets, val_preds, average='weighted')\n","val_rec = recall_score(val_targets, val_preds, average='weighted')\n","val_f1 = f1_score(val_targets, val_preds, average='weighted')\n","print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n","print(f\"Precision over the validation set: {val_prec:.4f}\")\n","print(f\"Recall over the validation set: {val_rec:.4f}\")\n","print(f\"F1 score over the validation set: {val_f1:.4f}\")\n","\n","# Generate confusion matrix for detailed error analysis\n","cm = confusion_matrix(val_targets, val_preds)\n","\n","# Create numeric labels for heatmap annotation\n","labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n","\n","# Visualise confusion matrix\n","plt.figure(figsize=(8, 7))\n","sns.heatmap(cm, annot=labels, fmt='',\n","            cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion Matrix ‚Äî Validation Set')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"x7hGgi1FeQkE"},"source":["### **Bidirectional Recurrent Neural Network (BiRNN)**\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1fU-SHapy-u1xHg8F-JApdOoX9Pz6kRmD\" width=\"800\"/>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K3J3yZdKMMz0"},"outputs":[],"source":["# Create model and display architecture with parameter count\n","rnn_model = RecurrentClassifier(\n","    input_size=input_shape[-1], # Pass the number of features\n","    hidden_size=HIDDEN_SIZE,\n","    num_layers=HIDDEN_LAYERS,\n","    num_classes=num_classes,\n","    dropout_rate=DROPOUT_RATE,\n","    bidirectional=True,\n","    rnn_type='RNN'\n","    ).to(device)\n","recurrent_summary(rnn_model, input_size=input_shape)\n","\n","# Set up TensorBoard logging and save model architecture\n","experiment_name = \"bi_rnn\"\n","writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n","x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n","writer.add_graph(rnn_model, x)\n","\n","# Define optimizer with L2 regularization\n","optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n","\n","# Enable mixed precision training for GPU acceleration\n","scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kV9fg6NENuF7"},"outputs":[],"source":["%%time\n","# Train model and track training history\n","rnn_model, training_history = fit(\n","    model=rnn_model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    epochs=EPOCHS,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    scaler=scaler,\n","    device=device,\n","    writer=writer,\n","    verbose=1,\n","    experiment_name=\"bi_rnn\",\n","    patience=PATIENCE\n","    )\n","\n","# Update best model if current performance is superior\n","if training_history['val_f1'][-1] > best_performance:\n","    best_model = rnn_model\n","    best_performance = training_history['val_f1'][-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"zOp65LGSOdNz"},"outputs":[],"source":["# @title Plot Hitory\n","# Create a figure with two side-by-side subplots (two columns)\n","fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n","\n","# Plot of training and validation loss on the first axis\n","ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n","ax1.set_title('Loss')\n","ax1.legend()\n","ax1.grid(alpha=0.3)\n","\n","# Plot of training and validation accuracy on the second axis\n","ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n","ax2.set_title('F1 Score')\n","ax2.legend()\n","ax2.grid(alpha=0.3)\n","\n","# Adjust the layout and display the plot\n","plt.tight_layout()\n","plt.subplots_adjust(right=0.85)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"cj7kCoICe5Ki"},"outputs":[],"source":["# @title Plot Confusion Matrix\n","# Collect predictions and ground truth labels\n","val_preds, val_targets = [], []\n","with torch.no_grad():  # Disable gradient computation for inference\n","    for xb, yb in val_loader:\n","        xb = xb.to(device)\n","\n","        # Forward pass: get model predictions\n","        logits = rnn_model(xb)\n","        preds = logits.argmax(dim=1).cpu().numpy()\n","\n","        # Store batch results\n","        val_preds.append(preds)\n","        val_targets.append(yb.numpy())\n","\n","# Combine all batches into single arrays\n","val_preds = np.concatenate(val_preds)\n","val_targets = np.concatenate(val_targets)\n","\n","# Calculate overall validation metrics\n","val_acc = accuracy_score(val_targets, val_preds)\n","val_prec = precision_score(val_targets, val_preds, average='weighted')\n","val_rec = recall_score(val_targets, val_preds, average='weighted')\n","val_f1 = f1_score(val_targets, val_preds, average='weighted')\n","print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n","print(f\"Precision over the validation set: {val_prec:.4f}\")\n","print(f\"Recall over the validation set: {val_rec:.4f}\")\n","print(f\"F1 score over the validation set: {val_f1:.4f}\")\n","\n","# Generate confusion matrix for detailed error analysis\n","cm = confusion_matrix(val_targets, val_preds)\n","\n","# Create numeric labels for heatmap annotation\n","labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n","\n","# Visualise confusion matrix\n","plt.figure(figsize=(8, 7))\n","sns.heatmap(cm, annot=labels, fmt='',\n","            cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion Matrix ‚Äî Validation Set')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"llBX--t7NAE3"},"source":["### **Long Short-Term Memory (LSTM)**\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1AHDpl1vMWow9xUhP4C7nZLJjk_kNos_I\" width=\"800\"/>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"astW9HWsOik3"},"outputs":[],"source":["# Create model and display architecture with parameter count\n","rnn_model = RecurrentClassifier(\n","    input_size=input_shape[-1], # Pass the number of features\n","    hidden_size=HIDDEN_SIZE,\n","    num_layers=HIDDEN_LAYERS,\n","    num_classes=num_classes,\n","    dropout_rate=DROPOUT_RATE,\n","    bidirectional=False,\n","    rnn_type='LSTM'\n","    ).to(device)\n","recurrent_summary(rnn_model, input_size=input_shape)\n","\n","# Set up TensorBoard logging and save model architecture\n","experiment_name = \"lstm\"\n","writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n","x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n","writer.add_graph(rnn_model, x)\n","\n","# Define optimizer with L2 regularization\n","optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n","\n","# Enable mixed precision training for GPU acceleration\n","scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bEuRDgEEOiiQ"},"outputs":[],"source":["%%time\n","# Train model and track training history\n","rnn_model, training_history = fit(\n","    model=rnn_model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    epochs=EPOCHS,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    scaler=scaler,\n","    device=device,\n","    writer=writer,\n","    verbose=1,\n","    experiment_name=\"lstm\",\n","    patience=PATIENCE\n","    )\n","\n","# Update best model if current performance is superior\n","if training_history['val_f1'][-1] > best_performance:\n","    best_model = rnn_model\n","    best_performance = training_history['val_f1'][-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Mt_ZjMnjOifb"},"outputs":[],"source":["# @title Plot Hitory\n","# Create a figure with two side-by-side subplots (two columns)\n","fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n","\n","# Plot of training and validation loss on the first axis\n","ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n","ax1.set_title('Loss')\n","ax1.legend()\n","ax1.grid(alpha=0.3)\n","\n","# Plot of training and validation accuracy on the second axis\n","ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n","ax2.set_title('F1 Score')\n","ax2.legend()\n","ax2.grid(alpha=0.3)\n","\n","# Adjust the layout and display the plot\n","plt.tight_layout()\n","plt.subplots_adjust(right=0.85)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"zxaww_Kne7m6"},"outputs":[],"source":["# @title Plot Confusion Matrix\n","# Collect predictions and ground truth labels\n","val_preds, val_targets = [], []\n","with torch.no_grad():  # Disable gradient computation for inference\n","    for xb, yb in val_loader:\n","        xb = xb.to(device)\n","\n","        # Forward pass: get model predictions\n","        logits = rnn_model(xb)\n","        preds = logits.argmax(dim=1).cpu().numpy()\n","\n","        # Store batch results\n","        val_preds.append(preds)\n","        val_targets.append(yb.numpy())\n","\n","# Combine all batches into single arrays\n","val_preds = np.concatenate(val_preds)\n","val_targets = np.concatenate(val_targets)\n","\n","# Calculate overall validation metrics\n","val_acc = accuracy_score(val_targets, val_preds)\n","val_prec = precision_score(val_targets, val_preds, average='weighted')\n","val_rec = recall_score(val_targets, val_preds, average='weighted')\n","val_f1 = f1_score(val_targets, val_preds, average='weighted')\n","print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n","print(f\"Precision over the validation set: {val_prec:.4f}\")\n","print(f\"Recall over the validation set: {val_rec:.4f}\")\n","print(f\"F1 score over the validation set: {val_f1:.4f}\")\n","\n","# Generate confusion matrix for detailed error analysis\n","cm = confusion_matrix(val_targets, val_preds)\n","\n","# Create numeric labels for heatmap annotation\n","labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n","\n","# Visualise confusion matrix\n","plt.figure(figsize=(8, 7))\n","sns.heatmap(cm, annot=labels, fmt='',\n","            cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion Matrix ‚Äî Validation Set')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"3bPCQoeXPjQY"},"source":["### **Bidirectional Long Short-Term Memory (BiLSTM)**\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1-W_s-cH_9wv-rmfKaa5giXzIXpdRFUpf\" width=\"800\"/>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SwQ_6RuoOick"},"outputs":[],"source":["# Create model and display architecture with parameter count\n","rnn_model = RecurrentClassifier(\n","    input_size=input_shape[-1], # Pass the number of features\n","    hidden_size=HIDDEN_SIZE,\n","    num_layers=HIDDEN_LAYERS,\n","    num_classes=num_classes,\n","    dropout_rate=DROPOUT_RATE,\n","    bidirectional=True,\n","    rnn_type='LSTM'\n","    ).to(device)\n","recurrent_summary(rnn_model, input_size=input_shape)\n","\n","# Set up TensorBoard logging and save model architecture\n","experiment_name = \"bi_lstm\"\n","writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n","x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n","writer.add_graph(rnn_model, x)\n","\n","# Define optimizer with L2 regularization\n","optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n","\n","# Enable mixed precision training for GPU acceleration\n","scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7yNxK3ctOiZ4"},"outputs":[],"source":["%%time\n","# Train model and track training history\n","rnn_model, training_history = fit(\n","    model=rnn_model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    epochs=EPOCHS,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    scaler=scaler,\n","    device=device,\n","    writer=writer,\n","    verbose=1,\n","    experiment_name=\"bi_lstm\",\n","    patience=PATIENCE\n","    )\n","\n","# Update best model if current performance is superior\n","if training_history['val_f1'][-1] > best_performance:\n","    best_model = rnn_model\n","    best_performance = training_history['val_f1'][-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YxWzzUO0fCY6","cellView":"form"},"outputs":[],"source":["# @title Plot Hitory\n","# Create a figure with two side-by-side subplots (two columns)\n","fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n","\n","# Plot of training and validation loss on the first axis\n","ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n","ax1.set_title('Loss')\n","ax1.legend()\n","ax1.grid(alpha=0.3)\n","\n","# Plot of training and validation accuracy on the second axis\n","ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n","ax2.set_title('F1 Score')\n","ax2.legend()\n","ax2.grid(alpha=0.3)\n","\n","# Adjust the layout and display the plot\n","plt.tight_layout()\n","plt.subplots_adjust(right=0.85)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oM09gbAJfCWK","cellView":"form"},"outputs":[],"source":["# @title Plot Confusion Matrix\n","# Collect predictions and ground truth labels\n","val_preds, val_targets = [], []\n","with torch.no_grad():  # Disable gradient computation for inference\n","    for xb, yb in val_loader:\n","        xb = xb.to(device)\n","\n","        # Forward pass: get model predictions\n","        logits = rnn_model(xb)\n","        preds = logits.argmax(dim=1).cpu().numpy()\n","\n","        # Store batch results\n","        val_preds.append(preds)\n","        val_targets.append(yb.numpy())\n","\n","# Combine all batches into single arrays\n","val_preds = np.concatenate(val_preds)\n","val_targets = np.concatenate(val_targets)\n","\n","# Calculate overall validation metrics\n","val_acc = accuracy_score(val_targets, val_preds)\n","val_prec = precision_score(val_targets, val_preds, average='weighted')\n","val_rec = recall_score(val_targets, val_preds, average='weighted')\n","val_f1 = f1_score(val_targets, val_preds, average='weighted')\n","print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n","print(f\"Precision over the validation set: {val_prec:.4f}\")\n","print(f\"Recall over the validation set: {val_rec:.4f}\")\n","print(f\"F1 score over the validation set: {val_f1:.4f}\")\n","\n","# Generate confusion matrix for detailed error analysis\n","cm = confusion_matrix(val_targets, val_preds)\n","\n","# Create numeric labels for heatmap annotation\n","labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n","\n","# Visualise confusion matrix\n","plt.figure(figsize=(8, 7))\n","sns.heatmap(cm, annot=labels, fmt='',\n","            cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion Matrix ‚Äî Validation Set')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"2FOn3o6tfCq2"},"source":["### **Gated Recurrent Unit (GRU)**\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1Ux7kRpO_9zgPfxITPjAsRZEOuVcJZVgg\" width=\"1000\"/>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kBA7z2FzOiY3"},"outputs":[],"source":["# Create model and display architecture with parameter count\n","rnn_model = RecurrentClassifier(\n","    input_size=input_shape[-1], # Pass the number of features\n","    hidden_size=HIDDEN_SIZE,\n","    num_layers=HIDDEN_LAYERS,\n","    num_classes=num_classes,\n","    dropout_rate=DROPOUT_RATE,\n","    bidirectional=False,\n","    rnn_type='GRU'\n","    ).to(device)\n","recurrent_summary(rnn_model, input_size=input_shape)\n","\n","# Set up TensorBoard logging and save model architecture\n","experiment_name = \"gru\"\n","writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n","x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n","writer.add_graph(rnn_model, x)\n","\n","# Define optimizer with L2 regularization\n","optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n","\n","# Enable mixed precision training for GPU acceleration\n","scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6RPjMvliOiUj"},"outputs":[],"source":["%%time\n","# Train model and track training history\n","rnn_model, training_history = fit(\n","    model=rnn_model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    epochs=EPOCHS,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    scaler=scaler,\n","    device=device,\n","    writer=writer,\n","    verbose=1,\n","    experiment_name=\"gru\",\n","    patience=20\n","    )\n","\n","# Update best model if current performance is superior\n","if training_history['val_f1'][-1] > best_performance:\n","    best_model = rnn_model\n","    best_performance = training_history['val_f1'][-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xFKwH_XDhh6A","cellView":"form"},"outputs":[],"source":["# @title Plot Hitory\n","# Create a figure with two side-by-side subplots (two columns)\n","fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n","\n","# Plot of training and validation loss on the first axis\n","ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n","ax1.set_title('Loss')\n","ax1.legend()\n","ax1.grid(alpha=0.3)\n","\n","# Plot of training and validation accuracy on the second axis\n","ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n","ax2.set_title('F1 Score')\n","ax2.legend()\n","ax2.grid(alpha=0.3)\n","\n","# Adjust the layout and display the plot\n","plt.tight_layout()\n","plt.subplots_adjust(right=0.85)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iUfoGj7hhh2S","cellView":"form"},"outputs":[],"source":["# @title Plot Confusion Matrix\n","# Collect predictions and ground truth labels\n","val_preds, val_targets = [], []\n","with torch.no_grad():  # Disable gradient computation for inference\n","    for xb, yb in val_loader:\n","        xb = xb.to(device)\n","\n","        # Forward pass: get model predictions\n","        logits = rnn_model(xb)\n","        preds = logits.argmax(dim=1).cpu().numpy()\n","\n","        # Store batch results\n","        val_preds.append(preds)\n","        val_targets.append(yb.numpy())\n","\n","# Combine all batches into single arrays\n","val_preds = np.concatenate(val_preds)\n","val_targets = np.concatenate(val_targets)\n","\n","# Calculate overall validation metrics\n","val_acc = accuracy_score(val_targets, val_preds)\n","val_prec = precision_score(val_targets, val_preds, average='weighted')\n","val_rec = recall_score(val_targets, val_preds, average='weighted')\n","val_f1 = f1_score(val_targets, val_preds, average='weighted')\n","print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n","print(f\"Precision over the validation set: {val_prec:.4f}\")\n","print(f\"Recall over the validation set: {val_rec:.4f}\")\n","print(f\"F1 score over the validation set: {val_f1:.4f}\")\n","\n","# Generate confusion matrix for detailed error analysis\n","cm = confusion_matrix(val_targets, val_preds)\n","\n","# Create numeric labels for heatmap annotation\n","labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n","\n","# Visualise confusion matrix\n","plt.figure(figsize=(8, 7))\n","sns.heatmap(cm, annot=labels, fmt='',\n","            cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion Matrix ‚Äî Validation Set')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"i-7wqXNbhiIF"},"source":["### **Bidirectional Gated Recurrent Unit (BiGRU)**\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1KH9dzVdNpSftSvWb2IXkBNcXAWwWVdhw\" width=\"800\"/>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41SvCLa9OiR4"},"outputs":[],"source":["# Create model and display architecture with parameter count\n","rnn_model = RecurrentClassifier(\n","    input_size=input_shape[-1], # Pass the number of features\n","    hidden_size=HIDDEN_SIZE,\n","    num_layers=HIDDEN_LAYERS,\n","    num_classes=num_classes,\n","    dropout_rate=DROPOUT_RATE,\n","    bidirectional=True,\n","    rnn_type='GRU'\n","    ).to(device)\n","recurrent_summary(rnn_model, input_size=input_shape)\n","\n","# Set up TensorBoard logging and save model architecture\n","experiment_name = \"bi_gru\"\n","writer = SummaryWriter(\"./\"+logs_dir+\"/\"+experiment_name)\n","x = torch.randn(1, input_shape[0], input_shape[1]).to(device)\n","writer.add_graph(rnn_model, x)\n","\n","# Define optimizer with L2 regularization\n","optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n","\n","# Enable mixed precision training for GPU acceleration\n","scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZBdVlkCOiO2"},"outputs":[],"source":["%%time\n","# Train model and track training history\n","rnn_model, training_history = fit(\n","    model=rnn_model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    epochs=EPOCHS,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    scaler=scaler,\n","    device=device,\n","    writer=writer,\n","    verbose=1,\n","    experiment_name=\"bi_gru\",\n","    patience=20\n","    )\n","\n","# Update best model if current performance is superior\n","if training_history['val_f1'][-1] > best_performance:\n","    best_model = rnn_model\n","    best_performance = training_history['val_f1'][-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ASP2DRnOiJT","cellView":"form"},"outputs":[],"source":["# @title Plot Hitory\n","# Create a figure with two side-by-side subplots (two columns)\n","fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n","\n","# Plot of training and validation loss on the first axis\n","ax1.plot(training_history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax1.plot(training_history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n","ax1.set_title('Loss')\n","ax1.legend()\n","ax1.grid(alpha=0.3)\n","\n","# Plot of training and validation accuracy on the second axis\n","ax2.plot(training_history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n","ax2.plot(training_history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n","ax2.set_title('F1 Score')\n","ax2.legend()\n","ax2.grid(alpha=0.3)\n","\n","# Adjust the layout and display the plot\n","plt.tight_layout()\n","plt.subplots_adjust(right=0.85)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pyEGX9ZomIqP","cellView":"form"},"outputs":[],"source":["# @title Plot Confusion Matrix\n","# Collect predictions and ground truth labels\n","val_preds, val_targets = [], []\n","with torch.no_grad():  # Disable gradient computation for inference\n","    for xb, yb in val_loader:\n","        xb = xb.to(device)\n","\n","        # Forward pass: get model predictions\n","        logits = rnn_model(xb)\n","        preds = logits.argmax(dim=1).cpu().numpy()\n","\n","        # Store batch results\n","        val_preds.append(preds)\n","        val_targets.append(yb.numpy())\n","\n","# Combine all batches into single arrays\n","val_preds = np.concatenate(val_preds)\n","val_targets = np.concatenate(val_targets)\n","\n","# Calculate overall validation metrics\n","val_acc = accuracy_score(val_targets, val_preds)\n","val_prec = precision_score(val_targets, val_preds, average='weighted')\n","val_rec = recall_score(val_targets, val_preds, average='weighted')\n","val_f1 = f1_score(val_targets, val_preds, average='weighted')\n","print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n","print(f\"Precision over the validation set: {val_prec:.4f}\")\n","print(f\"Recall over the validation set: {val_rec:.4f}\")\n","print(f\"F1 score over the validation set: {val_f1:.4f}\")\n","\n","# Generate confusion matrix for detailed error analysis\n","cm = confusion_matrix(val_targets, val_preds)\n","\n","# Create numeric labels for heatmap annotation\n","labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n","\n","# Visualise confusion matrix\n","plt.figure(figsize=(8, 7))\n","sns.heatmap(cm, annot=labels, fmt='',\n","            cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Confusion Matrix ‚Äî Validation Set')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hufUEx5ik-P7"},"outputs":[],"source":["# Copy TensorBoard logs to accessible location for Colab\n","!rsync -a $current_dir\"/\"$logs_dir/ \"/content/\"$logs_dir/\n","\n","# Launch TensorBoard interface\n","%tensorboard --logdir \"/content/\"$logs_dir"]},{"cell_type":"markdown","metadata":{"id":"t5VrQa_OMu74"},"source":["\n"]},{"cell_type":"markdown","source":["## **K-Shuffle-Split Cross Validation**"],"metadata":{"id":"7Gx84yscPhkp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8VYpD2qHXYf"},"outputs":[],"source":["# Cross-validation\n","K = 5                    # Number of splits (5 and 10 are considered good values)\n","N_VAL_USERS = 5          # Number of users for validation split\n","N_TEST_USERS = 5         # Number of users for test split\n","\n","# Training\n","EPOCHS = 500             # Maximum epochs (increase to improve performance)\n","PATIENCE = 50            # Early stopping patience (increase to improve performance)\n","VERBOSE = 10             # Print frequency\n","\n","# Optimisation\n","LEARNING_RATE = 1e-3     # Learning rate\n","BATCH_SIZE = 512         # Batch size\n","WINDOW_SIZE = 200        # Input window size\n","STRIDE = 50              # Input stride\n","\n","# Architecture\n","HIDDEN_LAYERS = 2        # Hidden layers\n","HIDDEN_SIZE = 128        # Neurons per layer\n","RNN_TYPE = 'GRU'         # Type of RNN architecture\n","BIDIRECTIONAL = False    # Bidirectional RNN\n","\n","# Regularisation\n","DROPOUT_RATE = 0.2       # Dropout probability\n","L1_LAMBDA = 0            # L1 penalty\n","L2_LAMBDA = 0            # L2 penalty\n","\n","# Training utilities\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hFfH7LKpHXWH"},"outputs":[],"source":["def k_shuffle_split_cross_validation_round_rnn(df, epochs, criterion, device,\n","                            k, n_val_users, n_test_users, batch_size, hidden_layers, hidden_size, learning_rate, dropout_rate,\n","                            window_size, stride, rnn_type, bidirectional,\n","                            l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n","                            restore_best_weights=True, writer=None, verbose=10, seed=42, experiment_name=\"\"):\n","    \"\"\"\n","    Perform K-fold shuffle split cross-validation with user-based splitting for time series data.\n","\n","    Args:\n","        df: DataFrame with columns ['user_id', 'activity', 'x_axis', 'y_axis', 'z_axis', 'id']\n","        epochs: Number of training epochs\n","        criterion: Loss function\n","        device: torch.device for computation\n","        k: Number of cross-validation splits\n","        n_val_users: Number of users for validation set\n","        n_test_users: Number of users for test set\n","        batch_size: Batch size for training\n","        hidden_layers: Number of recurrent layers\n","        hidden_size: Hidden state dimensionality\n","        learning_rate: Learning rate for optimizer\n","        dropout_rate: Dropout rate\n","        window_size: Length of sliding windows\n","        stride: Step size for sliding windows\n","        rnn_type: Type of RNN ('RNN', 'LSTM', 'GRU')\n","        bidirectional: Whether to use bidirectional RNN\n","        l1_lambda: L1 regularization coefficient (if used)\n","        l2_lambda: L2 regularization coefficient (weight_decay)\n","        patience: Early stopping patience\n","        evaluation_metric: Metric to monitor for early stopping\n","        mode: 'max' or 'min' for evaluation metric\n","        restore_best_weights: Whether to restore best weights after training\n","        writer: TensorBoard writer\n","        verbose: Verbosity level\n","        seed: Random seed\n","        experiment_name: Name for experiment logging\n","\n","    Returns:\n","        fold_losses: Dict with validation losses for each split\n","        fold_metrics: Dict with validation F1 scores for each split\n","        best_scores: Dict with best F1 score for each split plus mean and std\n","    \"\"\"\n","\n","    # Initialise containers for results across all splits\n","    fold_losses = {}\n","    fold_metrics = {}\n","    best_scores = {}\n","\n","    # Get model architecture parameters\n","    in_features = 3  # x_axis, y_axis, z_axis\n","    num_classes = len(df['activity'].unique())\n","\n","    # Initialise model architecture\n","    model = RecurrentClassifier(\n","        input_size=in_features,\n","        hidden_size=hidden_size,\n","        num_layers=hidden_layers,\n","        num_classes=num_classes,\n","        dropout_rate=dropout_rate,\n","        bidirectional=bidirectional,\n","        rnn_type=rnn_type\n","    ).to(device)\n","\n","    # Store initial weights to reset model for each split\n","    initial_state = copy.deepcopy(model.state_dict())\n","\n","    # Iterate through K random splits\n","    for split_idx in range(k):\n","\n","        if verbose > 0:\n","            print(f\"Split {split_idx+1}/{k}\")\n","\n","        # Get unique user IDs and shuffle them with split-specific seed\n","        unique_users = df['user_id'].unique()\n","        random.seed(seed + split_idx)\n","        random.shuffle(unique_users)\n","\n","        # Calculate the number of users for the training set\n","        n_train_users = len(unique_users) - n_val_users - n_test_users\n","\n","        # Split the shuffled user IDs into training, validation, and test sets\n","        train_users = unique_users[:n_train_users]\n","        val_users = unique_users[n_train_users:n_train_users + n_val_users]\n","        test_users = unique_users[n_train_users + n_val_users:]\n","\n","        # Split the dataset into training, validation, and test sets based on user IDs\n","        df_train = df[df['user_id'].isin(train_users)].copy()\n","        df_val = df[df['user_id'].isin(val_users)].copy()\n","        df_test = df[df['user_id'].isin(test_users)].copy()\n","\n","        # Define a mapping of activity names to integer labels\n","        label_mapping = {\n","            'Walking': 0,\n","            'Jogging': 1,\n","            'Upstairs': 2,\n","            'Downstairs': 3,\n","            'Sitting': 4,\n","            'Standing': 5\n","        }\n","\n","        # Map activity names to integers in the training set\n","        df_train['activity'] = df_train['activity'].map(label_mapping)\n","\n","        # Map activity names to integers in the validation set\n","        df_val['activity'] = df_val['activity'].map(label_mapping)\n","\n","        # Map activity names to integers in the test set\n","        df_test['activity'] = df_test['activity'].map(label_mapping)\n","\n","        if verbose > 0:\n","            print(f\"  Training set shape: {df_train.shape}\")\n","            print(f\"  Validation set shape: {df_val.shape}\")\n","            print(f\"  Test set shape: {df_test.shape}\")\n","\n","        # Normalise features using training set statistics\n","        train_max = df_train[['x_axis', 'y_axis', 'z_axis']].max()\n","        train_min = df_train[['x_axis', 'y_axis', 'z_axis']].min()\n","\n","        df_train[['x_axis', 'y_axis', 'z_axis']] = (df_train[['x_axis', 'y_axis', 'z_axis']] - train_min) / (train_max - train_min + 1e-8)\n","        df_val[['x_axis', 'y_axis', 'z_axis']] = (df_val[['x_axis', 'y_axis', 'z_axis']] - train_min) / (train_max - train_min + 1e-8)\n","        df_test[['x_axis', 'y_axis', 'z_axis']] = (df_test[['x_axis', 'y_axis', 'z_axis']] - train_min) / (train_max - train_min + 1e-8)\n","\n","        # Build sequences using the existing build_sequences function\n","        X_train, y_train = build_sequences(df_train, window=window_size, stride=stride)\n","        X_val, y_val = build_sequences(df_val, window=window_size, stride=stride)\n","        X_test, y_test = build_sequences(df_test, window=window_size, stride=stride)\n","\n","        if verbose > 0:\n","            print(f\"  Training sequences shape: {X_train.shape}\")\n","            print(f\"  Validation sequences shape: {X_val.shape}\")\n","            print(f\"  Test sequences shape: {X_test.shape}\")\n","\n","        # Create PyTorch datasets\n","        train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n","        val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n","        test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n","\n","        # Create data loaders\n","        train_loader = make_loader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n","        val_loader   = make_loader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n","        test_loader  = make_loader(test_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n","\n","        # Reset model to initial weights for fair comparison across splits\n","        model.load_state_dict(initial_state)\n","\n","        # Define optimizer with L2 regularization\n","        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=l2_lambda)\n","\n","        # Enable mixed precision training for GPU acceleration\n","        split_scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n","\n","        # Create directory for model checkpoints\n","        os.makedirs(f\"models/{experiment_name}\", exist_ok=True)\n","\n","        # Train model on current split\n","        model, training_history = fit(\n","            model=model,\n","            train_loader=train_loader,\n","            val_loader=val_loader,\n","            epochs=epochs,\n","            criterion=criterion,\n","            optimizer=optimizer,\n","            scaler=split_scaler,\n","            device=device,\n","            writer=writer,\n","            patience=patience,\n","            verbose=verbose,\n","            l1_lambda=l1_lambda,\n","            evaluation_metric=evaluation_metric,\n","            mode=mode,\n","            restore_best_weights=restore_best_weights,\n","            experiment_name=experiment_name+\"/split_\"+str(split_idx)\n","        )\n","\n","        # Store results for this split\n","        fold_losses[f\"split_{split_idx}\"] = training_history['val_loss']\n","        fold_metrics[f\"split_{split_idx}\"] = training_history['val_f1']\n","        best_scores[f\"split_{split_idx}\"] = max(training_history['val_f1'])\n","\n","    # Compute mean and standard deviation of best scores across splits\n","    best_scores[\"mean\"] = np.mean([best_scores[k] for k in best_scores.keys() if k.startswith(\"split_\")])\n","    best_scores[\"std\"] = np.std([best_scores[k] for k in best_scores.keys() if k.startswith(\"split_\")])\n","\n","    if verbose > 0:\n","        print(f\"Best score: {best_scores['mean']:.4f}¬±{best_scores['std']:.4f}\")\n","\n","    return fold_losses, fold_metrics, best_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cw59lTVZHXTs"},"outputs":[],"source":["%%time\n","# Execute K-fold cross-validation with baseline configuration\n","losses, metrics, best_scores = k_shuffle_split_cross_validation_round_rnn(\n","    df=df,\n","    epochs=EPOCHS,\n","    criterion=criterion,\n","    device=device,\n","    k=K,\n","    batch_size=BATCH_SIZE,\n","    hidden_layers=HIDDEN_LAYERS,\n","    hidden_size=HIDDEN_SIZE,\n","    learning_rate=LEARNING_RATE,\n","    dropout_rate=DROPOUT_RATE,\n","    l1_lambda=L1_LAMBDA,\n","    l2_lambda=L2_LAMBDA,\n","    verbose=VERBOSE,\n","    patience=PATIENCE,\n","    seed=SEED,\n","    experiment_name=\"gru_baseline\",\n","    n_val_users=N_VAL_USERS,\n","    n_test_users=N_TEST_USERS,\n","    window_size=WINDOW_SIZE,\n","    stride=STRIDE,\n","    rnn_type=RNN_TYPE,\n","    bidirectional=BIDIRECTIONAL\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"fq7WbKm0NuDv"},"outputs":[],"source":["# @title Plot Hitory\n","# Create figure with two subplots sharing x axis\n","fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(18, 5), sharex=True)\n","\n","# Color palette for K splits\n","colors = plt.cm.get_cmap('tab10', K)\n","\n","# Plot validation loss for each split\n","for split in range(K):\n","    axes[0].plot(losses[f'split_{split}'][:-PATIENCE], label=f'Split {split+1}',\n","                 color=colors(split), alpha=0.6)\n","axes[0].set_title('Validation Loss per Split')\n","axes[0].set_ylabel('Loss')\n","axes[0].set_xlabel('Epoch')\n","axes[0].grid(alpha=0.3)\n","\n","# Plot validation F1 score for each split\n","for split in range(K):\n","    axes[1].plot(metrics[f'split_{split}'][:-PATIENCE], label=f'Split {split+1}',\n","                 color=colors(split), alpha=0.6)\n","axes[1].set_title('Validation F1 Score per Split')\n","axes[1].set_ylabel('F1 Score')\n","axes[1].set_xlabel('Epoch')\n","axes[1].grid(alpha=0.3)\n","\n","# Add shared legend on the right\n","handles, labels = axes[0].get_legend_handles_labels()\n","fig.legend(handles, labels, loc='center left', bbox_to_anchor=(1, 0.5), fontsize='small')\n","\n","# Adjust layout\n","plt.tight_layout()\n","plt.subplots_adjust(right=0.975)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"QpMYvRFvNuDv"},"source":["## **Hyperparameters Tuning**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QPlepEPwHXOo"},"outputs":[],"source":["def grid_search_cv_rnn(df, param_grid, fixed_params, cv_params, verbose=True):\n","    \"\"\"\n","    Execute grid search with K-shuffle-split cross-validation for RNN models on time series data.\n","\n","    Args:\n","        df: DataFrame with columns ['user_id', 'activity', 'x_axis', 'y_axis', 'z_axis', 'id']\n","        param_grid: Dict of parameters to test, e.g. {'batch_size': [16, 32], 'rnn_type': ['LSTM', 'GRU']}\n","        fixed_params: Dict of fixed hyperparameters (hidden_size, learning_rate, window_size, stride, etc.)\n","        cv_params: Dict of CV settings (epochs, k, patience, criterion, scaler, device, etc.)\n","        verbose: Print progress for each configuration\n","\n","    Returns:\n","        results: Dict with scores for each configuration\n","        best_config: Dict with best hyperparameter combination\n","        best_score: Best mean F1 score achieved\n","    \"\"\"\n","    # Generate all parameter combinations\n","    param_names = list(param_grid.keys())\n","    param_values = list(param_grid.values())\n","    combinations = list(product(*param_values))\n","\n","    results = {}\n","    best_score = -np.inf\n","    best_config = None\n","\n","    total = len(combinations)\n","\n","    for idx, combo in enumerate(combinations, 1):\n","        # Create current configuration dict\n","        current_config = dict(zip(param_names, combo))\n","        config_str = \"_\".join([f\"{k}_{v}\" for k, v in current_config.items()])\n","\n","        if verbose:\n","            print(f\"\\nConfiguration {idx}/{total}:\")\n","            for param, value in current_config.items():\n","                print(f\"  {param}: {value}\")\n","\n","        # Merge current config with fixed parameters\n","        run_params = {**fixed_params, **current_config}\n","\n","        # Execute cross-validation\n","        _, _, fold_scores = k_shuffle_split_cross_validation_round_rnn(\n","            df=df,\n","            experiment_name=config_str,\n","            **run_params,\n","            **cv_params\n","        )\n","\n","        # Store results\n","        results[config_str] = fold_scores\n","\n","        # Track best configuration\n","        if fold_scores[\"mean\"] > best_score:\n","            best_score = fold_scores[\"mean\"]\n","            best_config = current_config.copy()\n","            if verbose:\n","                print(\"  NEW BEST SCORE!\")\n","\n","        if verbose:\n","            print(f\"  F1 Score: {fold_scores['mean']:.4f}¬±{fold_scores['std']:.4f}\")\n","\n","    return results, best_config, best_score\n","\n","\n","def plot_top_configurations_rnn(results, k_splits, top_n=5, figsize=(14, 7)):\n","    \"\"\"\n","    Visualise top N RNN configurations with boxplots of F1 scores across CV splits.\n","\n","    Args:\n","        results: Dict of results from grid_search_cv_rnn\n","        k_splits: Number of CV splits used\n","        top_n: Number of top configurations to display\n","        figsize: Figure size tuple\n","    \"\"\"\n","    # Sort by mean score\n","    config_scores = {name: data['mean'] for name, data in results.items()}\n","    sorted_configs = sorted(config_scores.items(), key=lambda x: x[1], reverse=True)\n","\n","    # Select top N\n","    top_configs = sorted_configs[:min(top_n, len(sorted_configs))]\n","\n","    # Prepare boxplot data\n","    boxplot_data = []\n","    labels = []\n","\n","    # Define a dictionary for replacements, ordered to handle prefixes correctly\n","    replacements = {\n","        'batch_size_': 'BS=',\n","        'learning_rate_': '\\nLR=',\n","        'hidden_layers_': '\\nHL=',\n","        'hidden_size_': '\\nHS=',\n","        'dropout_rate_': '\\nDR=',\n","        'window_size_': '\\nWS=',\n","        'stride_': '\\nSTR=',\n","        'rnn_type_': '\\nRNN=',\n","        'bidirectional_': '\\nBIDIR=',\n","        'l1_lambda_': '\\nL1=',\n","        'l2_lambda_': '\\nL2='\n","    }\n","\n","    # Replacements for separators\n","    separator_replacements = {\n","        '_learning_rate_': '\\nLR=',\n","        '_hidden_layers_': '\\nHL=',\n","        '_hidden_size_': '\\nHS=',\n","        '_dropout_rate_': '\\nDR=',\n","        '_window_size_': '\\nWS=',\n","        '_stride_': '\\nSTR=',\n","        '_rnn_type_': '\\nRNN=',\n","        '_bidirectional_': '\\nBIDIR=',\n","        '_l1_lambda_': '\\nL1=',\n","        '_l2_lambda_': '\\nL2=',\n","        '_': ''\n","    }\n","\n","    for config_name, mean_score in top_configs:\n","        # Extract best score from each split (auto-detect number of splits)\n","        split_scores = []\n","        for i in range(k_splits):\n","            if f'split_{i}' in results[config_name]:\n","                split_scores.append(results[config_name][f'split_{i}'])\n","        boxplot_data.append(split_scores)\n","\n","        # Verify we have the expected number of splits\n","        if len(split_scores) != k_splits:\n","            print(f\"Warning: Config {config_name} has {len(split_scores)} splits, expected {k_splits}\")\n","\n","        # Create readable label using the replacements dictionary\n","        readable_label = config_name\n","        for old, new in replacements.items():\n","            readable_label = readable_label.replace(old, new)\n","\n","        # Apply separator replacements\n","        for old, new in separator_replacements.items():\n","             readable_label = readable_label.replace(old, new)\n","\n","        labels.append(f\"{readable_label}\\n(Œº={mean_score:.3f})\")\n","\n","    # Create plot\n","    fig, ax = plt.subplots(figsize=figsize)\n","    bp = ax.boxplot(boxplot_data, labels=labels, patch_artist=True,\n","                    showmeans=True, meanline=True)\n","\n","    # Styling\n","    for patch in bp['boxes']:\n","        patch.set_facecolor('lightblue')\n","        patch.set_alpha(0.7)\n","\n","    # Highlight best configuration\n","    ax.get_xticklabels()[0].set_fontweight('bold')\n","\n","    ax.set_ylabel('F1 Score')\n","    ax.set_xlabel('Configuration')\n","    ax.set_title(f'Top {len(top_configs)} RNN Configurations - F1 Score Distribution Across {k_splits} Splits')\n","    ax.grid(alpha=0.3, axis='y')\n","\n","    plt.xticks(rotation=0, ha='center')\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zbD8awRDHXML"},"outputs":[],"source":["%%time\n","# Define parameters to search\n","param_grid = {\n","    'window_size': [50, 100, 200, 400],\n","    'stride': [25, 50],\n","}\n","\n","# Fixed hyperparameters (not being tuned)\n","fixed_params = {\n","    'batch_size': BATCH_SIZE,\n","    'learning_rate': LEARNING_RATE,\n","    'hidden_layers': HIDDEN_LAYERS,\n","    'hidden_size': HIDDEN_SIZE,\n","    'dropout_rate': DROPOUT_RATE,\n","    'l1_lambda': L1_LAMBDA,\n","    'l2_lambda': L2_LAMBDA,\n","    'rnn_type': RNN_TYPE,\n","    'bidirectional': BIDIRECTIONAL\n","}\n","\n","# Cross-validation settings\n","cv_params = {\n","    'epochs': EPOCHS,\n","    'criterion': criterion,\n","    'device': device,\n","    'k': K,\n","    'n_val_users': N_VAL_USERS,\n","    'n_test_users': N_TEST_USERS,\n","    'patience': PATIENCE,\n","    'verbose': 0,\n","    'seed': SEED\n","}\n","\n","# Execute search\n","results, best_config, best_score = grid_search_cv_rnn(\n","    df=df,\n","    param_grid=param_grid,\n","    fixed_params=fixed_params,\n","    cv_params=cv_params\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ImYxq6AsHXJv"},"outputs":[],"source":["# Visualise results\n","plot_top_configurations_rnn(results, k_splits=K, top_n=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eytiPUW_NuDw"},"outputs":[],"source":["# %%time\n","# --- 1. Combine fixed and best hyperparameters ---\n","# 'fixed_params' and 'best_config' are loaded from the grid search cell\n","final_best_params = {**fixed_params, **best_config}\n","\n","# Generate config string (from grid params only) to find saved model files\n","best_config_str = \"_\".join([f\"{k}_{v}\" for k, v in best_config.items()])\n","\n","# Initialise lists for metrics\n","test_accuracies = []\n","test_precisions = []\n","test_recall_scores = []\n","test_f1_scores = []\n","all_test_targets = [] # For aggregated confusion matrix\n","all_test_preds = []   # For aggregated confusion matrix\n","\n","label_mapping = {\n","    'Walking': 0, 'Jogging': 1, 'Upstairs': 2,\n","    'Downstairs': 3, 'Sitting': 4, 'Standing': 5\n","}\n","scale_columns = ['x_axis', 'y_axis', 'z_axis']\n","\n","# --- 2. Begin evaluation loop across the K splits ---\n","# K, SEED, N_VAL_USERS, N_TEST_USERS are defined globally\n","for split in range(K):\n","    print(f\"Evaluating Split {split+1}/{K} using best config: {best_config_str}\")\n","\n","    # --- 3. Regenerate the exact data split for this fold ---\n","    # This logic must be identical to k_shuffle_split_cross_validation_round_rnn\n","    unique_users = df['user_id'].unique()\n","    random.seed(SEED + split) # Use the same CV seed\n","    random.shuffle(unique_users)\n","\n","    n_train_users = len(unique_users) - N_VAL_USERS - N_TEST_USERS\n","    train_users = unique_users[:n_train_users]\n","    val_users = unique_users[n_train_users:n_train_users + N_VAL_USERS]\n","    test_users = unique_users[n_train_users + N_VAL_USERS:]\n","\n","    df_train = df[df['user_id'].isin(train_users)].copy()\n","    df_test = df[df['user_id'].isin(test_users)].copy()\n","\n","    # --- 4. Preprocess the data ---\n","    df_train['activity'] = df_train['activity'].map(label_mapping)\n","    df_test['activity'] = df_test['activity'].map(label_mapping)\n","\n","    # Normalise features (fit on THIS split's training data)\n","    mins = df_train[scale_columns].min()\n","    maxs = df_train[scale_columns].max()\n","\n","    for column in scale_columns:\n","        df_test[column] = (df_test[column] - mins[column]) / (maxs[column] - mins[column] + 1e-8)\n","\n","    # --- 5. Build test sequences ---\n","    # Use the best window/stride from final_best_params\n","    X_test, y_test = build_sequences(\n","        df_test,\n","        window=final_best_params['window_size'],\n","        stride=final_best_params['stride']\n","    )\n","\n","    # --- 6. Create the Test DataLoader ---\n","    test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n","    test_loader  = make_loader(\n","        test_ds,\n","        batch_size=final_best_params['batch_size'],\n","        shuffle=False,\n","        drop_last=False\n","    )\n","\n","    # Handle empty test sets from user splits\n","    if len(test_ds) == 0:\n","        print(f\"  WARNING: Test set for split {split+1} is empty. Skipping.\")\n","        continue\n","\n","    # --- 7. Initialise the Model ---\n","    # Use the best architecture parameters from the grid search\n","    model = RecurrentClassifier(\n","        input_size=X_test.shape[2], # num_features (3)\n","        hidden_size=final_best_params['hidden_size'],\n","        num_layers=final_best_params['hidden_layers'],\n","        num_classes=len(label_mapping), # num_classes (6)\n","        dropout_rate=final_best_params['dropout_rate'],\n","        bidirectional=final_best_params['bidirectional'],\n","        rnn_type=final_best_params['rnn_type']\n","    ).to(device)\n","\n","    # --- 8. Load the model weights for this specific split and config ---\n","    model_path = f\"models/{best_config_str}/split_{split}_model.pt\"\n","\n","    try:\n","        model.load_state_dict(torch.load(model_path, map_location=device))\n","    except FileNotFoundError:\n","        print(f\"  ERROR: Model file not found at {model_path}\")\n","        print(f\"  Skipping split {split+1}.\")\n","        continue\n","\n","    model.eval() # Set model to evaluation mode\n","\n","    # --- 9. Run predictions on the test set ---\n","    split_test_preds, split_test_targets = [], []\n","    with torch.no_grad(): # Disable gradient computation for inference\n","        for xb, yb in test_loader:\n","            xb = xb.to(device)\n","            logits = model(xb)\n","            preds = logits.argmax(dim=1).cpu().numpy()\n","            split_test_preds.append(preds)\n","            split_test_targets.append(yb.numpy())\n","\n","    split_test_preds = np.concatenate(split_test_preds)\n","    split_test_targets = np.concatenate(split_test_targets)\n","\n","    # --- 10. Calculate and store metrics for this split ---\n","    split_test_acc = accuracy_score(split_test_targets, split_test_preds)\n","    split_test_prec = precision_score(split_test_targets, split_test_preds, average='weighted', zero_division=0)\n","    split_test_rec = recall_score(split_test_targets, split_test_preds, average='weighted', zero_division=0)\n","    split_test_f1 = f1_score(split_test_targets, split_test_preds, average='weighted', zero_division=0)\n","\n","    print(f\"  Test F1 Score for Split {split+1}: {split_test_f1:.4f}\")\n","\n","    test_accuracies.append(split_test_acc)\n","    test_precisions.append(split_test_prec)\n","    test_recall_scores.append(split_test_rec)\n","    test_f1_scores.append(split_test_f1)\n","\n","    all_test_targets.extend(split_test_targets)\n","    all_test_preds.extend(split_test_preds)\n","\n","\n","# --- 11. After the loop: Print mean metrics and plot confusion matrix ---\n","print(\"\\nAverage metrics across all splits on the test set:\")\n","print(f\"Mean Accuracy: {np.mean(test_accuracies):.4f} ¬± {np.std(test_accuracies):.4f}\")\n","print(f\"Mean Precision: {np.mean(test_precisions):.4f} ¬± {np.std(test_precisions):.4f}\")\n","print(f\"Mean Recall: {np.mean(test_recall_scores):.4f} ¬± {np.std(test_recall_scores):.4f}\")\n","print(f\"Mean F1 score: {np.mean(test_f1_scores):.4f} ¬± {np.std(test_f1_scores):.4f}\")\n","\n","\n","# Generate confusion matrix for the concatenated test sets\n","cm = confusion_matrix(all_test_targets, all_test_preds)\n","labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n","\n","# Visualise confusion matrix\n","plt.figure(figsize=(8, 7))\n","sns.heatmap(cm, annot=labels, fmt='',\n","            cmap='Blues')\n","plt.xlabel('Predicted labels')\n","plt.ylabel('True labels')\n","plt.title('Aggregated Confusion Matrix ‚Äî Test Sets Across Splits')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"et_9CJzIBsRt"},"source":["#  \n","<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n","\n","##### Connect with us:\n","- <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"14\"> **LinkedIn:**  [AIRLab Polimi](https://www.linkedin.com/company/airlab-polimi/)\n","- <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"14\"> **Instagram:** [airlab_polimi](https://www.instagram.com/airlab_polimi/)\n","\n","##### Contributors:\n","- **Eugenio Lomurno**: eugenio.lomurno@polimi.it\n","- **Alberto Archetti**: alberto.archetti@polimi.it\n","- **Roberto Basla**: roberto.basla@polimi.it\n","- **Carlo Sgaravatti**: carlo.sgaravatti@polimi.it\n","\n","```\n","   Copyright 2025 Eugenio Lomurno, Alberto Archetti, Roberto Basla, Carlo Sgaravatti\n","\n","   Licensed under the Apache License, Version 2.0 (the \"License\");\n","   you may not use this file except in compliance with the License.\n","   You may obtain a copy of the License at\n","\n","       http://www.apache.org/licenses/LICENSE-2.0\n","\n","   Unless required by applicable law or agreed to in writing, software\n","   distributed under the License is distributed on an \"AS IS\" BASIS,\n","   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","   See the License for the specific language governing permissions and\n","   limitations under the License.\n","```"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["3bPCQoeXPjQY"]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.12"}},"nbformat":4,"nbformat_minor":0}